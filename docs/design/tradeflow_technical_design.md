# TradeFlow MVP æŠ€æœ¯è®¾è®¡æ–‡æ¡£

## ç›®å½•
1. [æ‰§è¡Œæ‘˜è¦](#æ‰§è¡Œæ‘˜è¦)
2. [ç³»ç»Ÿæ¶æ„è®¾è®¡](#ç³»ç»Ÿæ¶æ„è®¾è®¡)
3. [æ•°æ®æ¶æ„è®¾è®¡](#æ•°æ®æ¶æ„è®¾è®¡)
4. [APIè®¾è®¡](#apiè®¾è®¡)
5. [Google ADK Agentå¼€å‘æ–¹æ¡ˆ](#google-adk-agentå¼€å‘æ–¹æ¡ˆ)
6. [ç¬¬ä¸‰æ–¹ç™»å½•é›†æˆ](#ç¬¬ä¸‰æ–¹ç™»å½•é›†æˆ)
7. [å¤šè¯­è¨€æ”¯æŒç­–ç•¥](#å¤šè¯­è¨€æ”¯æŒç­–ç•¥)
8. [éƒ¨ç½²æ¶æ„](#éƒ¨ç½²æ¶æ„)
9. [æ€§èƒ½ä¼˜åŒ–ç­–ç•¥](#æ€§èƒ½ä¼˜åŒ–ç­–ç•¥)
10. [æµ‹è¯•æ–¹æ¡ˆ](#æµ‹è¯•æ–¹æ¡ˆ)
11. [é£é™©ä¸ç¼“è§£æªæ–½](#é£é™©ä¸ç¼“è§£æªæ–½)
12. [å®æ–½è®¡åˆ’](#å®æ–½è®¡åˆ’)

---

## æ‰§è¡Œæ‘˜è¦

### é¡¹ç›®èƒŒæ™¯
TradeFlowæ˜¯ä¸€æ¬¾åŸºäºAIçš„B2Bè´¸æ˜“æ™ºèƒ½åŠ©æ‰‹ï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€äº¤äº’å¸®åŠ©ç”¨æˆ·å®Œæˆä¹°å®¶å¼€å‘ã€ä¾›åº”å•†é‡‡è´­ç­‰è´¸æ˜“ä¸šåŠ¡ã€‚æœ¬æ–‡æ¡£ä¸º3-4ä¸ªæœˆMVPç‰ˆæœ¬çš„æŠ€æœ¯è®¾è®¡æ–¹æ¡ˆã€‚

### æ ¸å¿ƒæŠ€æœ¯å†³ç­–
- **AIæ¡†æ¶**: Google ADK (Agent Development Kit)
- **åç«¯**: FastAPI (Python)
- **å‰ç«¯**: React
- **æ•°æ®åº“**: PostgreSQLï¼ˆç»“æ„åŒ–æ•°æ®ï¼‰ + MongoDBï¼ˆå¯¹è¯æ•°æ®ï¼‰ + Redisï¼ˆç¼“å­˜ï¼‰
- **è®¤è¯**: OAuth 2.0 (Google, GitHub)
- **éƒ¨ç½²**: Docker + Cloud Run

### è®¾è®¡åŸåˆ™
1. **ç®€æ´å®ç”¨**: é¿å…è¿‡åº¦å·¥ç¨‹åŒ–ï¼Œä¸“æ³¨MVPæ ¸å¿ƒåŠŸèƒ½
2. **å¯æ‰©å±•æ€§**: æ¨¡å—åŒ–è®¾è®¡ï¼Œä¾¿äºåç»­è¿­ä»£
3. **ç”¨æˆ·ä½“éªŒ**: ä¼˜å…ˆä¿è¯å“åº”é€Ÿåº¦å’Œæ˜“ç”¨æ€§
4. **å®‰å…¨åˆè§„**: éµå¾ªæ•°æ®å®‰å…¨å’Œéšç§ä¿æŠ¤æ ‡å‡†

---

## ç³»ç»Ÿæ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„å›¾

```mermaid
graph TD
    subgraph "Frontend Layer"
        A[React App SPA]
        B[i18n Support] 
        C[OAuth Client]
        D1[File Preview Panel]
    end
    
    subgraph "API Gateway Layer"
        D[FastAPI REST API]
        E[SSE Handler]
        F[Auth Middleware]
    end
    
    subgraph "Business Logic Layer"
        G[Agent Gateway Service]
        H[Business Services]
        I[Payment Service]
        P[File Service]
    end
    
    subgraph "Google ADK Agent Layer"
        J[Buyer Agent]
        K[Supplier Agent]
        L[Market Analysis Agent]
    end
    
    subgraph "Data Layer"
        M[PostgreSQL<br/>Structured + Files]
        N[MongoDB<br/>Dialogues]
        O[Redis<br/>Cache]
        Q[MinIO<br/>Object Storage]
    end
    
    A --> D
    A -.-> E
    B --> D
    C --> D
    D1 --> D
    
    D --> G
    D --> P
    E --> G
    F --> D
    F --> E
    
    G --> J
    G --> K
    G --> L
    H --> M
    I --> M
    P --> M
    P --> Q
    
    J --> N
    K --> N
    L --> N
    J --> P
    K --> P
    L --> P
    G --> O
```

### æ ¸å¿ƒç»„ä»¶è¯´æ˜

#### 1. Frontend Layer
- **React SPA**: å•é¡µåº”ç”¨ï¼Œæä¾›æµç•…çš„ç”¨æˆ·ä½“éªŒ
- **i18n Support**: åŸºäºReact-i18nextçš„å¤šè¯­è¨€æ”¯æŒ
- **OAuth Client**: å¤„ç†Google/GitHubç¬¬ä¸‰æ–¹ç™»å½•
- **File Preview Panel**: å³ä¾§æ–‡ä»¶é¢„è§ˆé¢æ¿ï¼Œæ”¯æŒå¯¹è¯ä¸­ç”Ÿæˆæ–‡ä»¶çš„é¢„è§ˆå’Œç®¡ç†

#### 2. API Gateway Layer
- **FastAPI REST**: æä¾›RESTful APIæ¥å£
- **SSE Handler**: æ”¯æŒå®æ—¶å¯¹è¯æµå¼å“åº”
- **Auth Middleware**: JWT tokenéªŒè¯å’Œæƒé™æ§åˆ¶

#### 3. Business Logic Layer
- **Agent Gateway Service**: ç»Ÿä¸€çš„Agentè°ƒåº¦å’Œç®¡ç†
- **Business Services**: ç”¨æˆ·ç®¡ç†ã€äº§å“ç®¡ç†ã€äº¤æ˜“ç®¡ç†ç­‰
- **Payment Service**: Stripeæ”¯ä»˜é›†æˆ
- **File Service**: æ–‡ä»¶ä¸Šä¼ ã€å­˜å‚¨ã€é¢„è§ˆå’Œç®¡ç†æœåŠ¡ï¼Œæ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼

#### 4. Google ADK Agent Layer ã€âœ… å·²å®ç°ã€‘
> **å®ç°çŠ¶æ€**: å·²é€šè¿‡ADKç‹¬ç«‹å¼€å‘å®Œæˆï¼Œä½äº `src/agent/TradeFlowAgent/`

- **Main Orchestrator Agent**: ç³»ç»Ÿçº§ReActä¸»åè°ƒå™¨ âœ…
- **Search Agent**: ç½‘ç»œæœç´¢ä¸“å®¶ âœ…
- **Trade Agent**: è´¸æ˜“æ•°æ®ä¸“å®¶ï¼ˆæµ·å…³æ•°æ®æŸ¥è¯¢ï¼‰ âœ…
- **Company Agent**: ä¼ä¸šä¿¡æ¯ä¸“å®¶ âœ…
- **Enterprise Discovery Agent**: ä¼ä¸šå‘ç°ä¸“å®¶ï¼ˆä¾›åº”å•†åŒ¹é…ï¼‰ âœ…
- **Web Analyzer Agent**: å•†å“é¡µé¢è§£æä¸“å®¶ âœ…

#### 5. Data Layer
- **PostgreSQL**: å­˜å‚¨ç”¨æˆ·ã€ä¼ä¸šã€äº§å“ç­‰ç»“æ„åŒ–æ•°æ®ï¼Œä»¥åŠæ–‡ä»¶å…ƒæ•°æ®
- **MongoDB**: å­˜å‚¨å¯¹è¯å†å²ã€Agentä¸Šä¸‹æ–‡ç­‰éç»“æ„åŒ–æ•°æ®
- **Redis**: ä¼šè¯ç¼“å­˜ã€APIé™æµã€çƒ­ç‚¹æ•°æ®ç¼“å­˜
- **MinIO**: å¯¹è±¡å­˜å‚¨æœåŠ¡ï¼Œå­˜å‚¨Agentç”Ÿæˆçš„æ–‡ä»¶å’Œç”¨æˆ·ä¸Šä¼ çš„æ–‡æ¡£

---

## æ•°æ®æ¶æ„è®¾è®¡

### PostgreSQL Schemaï¼ˆç»“æ„åŒ–æ•°æ®ï¼‰

```sql
-- ç”¨æˆ·è¡¨ï¼ˆæ”¯æŒOAuthï¼‰
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE,
    name VARCHAR(255),
    avatar_url TEXT,
    auth_provider VARCHAR(50), -- 'google', 'github', 'email'
    auth_provider_id VARCHAR(255),
    language_preference VARCHAR(10) DEFAULT 'en',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ä¼ä¸šè®¤è¯è¡¨
CREATE TABLE companies (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    company_name VARCHAR(255) NOT NULL,
    company_type VARCHAR(50), -- 'manufacturer', 'trader', 'buyer'
    country VARCHAR(2),
    business_license TEXT,
    verification_status VARCHAR(50) DEFAULT 'pending',
    trust_score INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- äº§å“è¡¨
CREATE TABLE products (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id UUID REFERENCES companies(id),
    name VARCHAR(255) NOT NULL,
    category VARCHAR(100),
    description TEXT,
    hs_code VARCHAR(20),
    price_range JSONB,
    moq INTEGER,
    images JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ä½¿ç”¨è®°å½•è¡¨
CREATE TABLE usage_records (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    action_type VARCHAR(50), -- 'chat', 'recommendation', 'export'
    tokens_used INTEGER,
    cost DECIMAL(10, 4),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- è®¢é˜…å’Œæ”¯ä»˜è¡¨
CREATE TABLE subscriptions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    stripe_customer_id VARCHAR(255),
    stripe_subscription_id VARCHAR(255),
    plan_type VARCHAR(50),
    credits_remaining INTEGER,
    status VARCHAR(50),
    expires_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ–‡ä»¶å…ƒæ•°æ®è¡¨
CREATE TABLE files (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    conversation_id VARCHAR(255), -- å…³è”çš„å¯¹è¯ID
    filename VARCHAR(255) NOT NULL,
    original_filename VARCHAR(255) NOT NULL,
    file_type VARCHAR(50) NOT NULL, -- 'image', 'document', 'code', 'data'
    file_extension VARCHAR(10) NOT NULL,
    content_type VARCHAR(100) NOT NULL,
    file_size BIGINT NOT NULL,
    minio_bucket VARCHAR(100) NOT NULL,
    minio_object_key VARCHAR(500) NOT NULL,
    description TEXT,
    tags JSONB,
    is_generated BOOLEAN DEFAULT false, -- æ˜¯å¦ä¸ºAgentç”Ÿæˆçš„æ–‡ä»¶
    preview_content TEXT, -- é¢„è§ˆå†…å®¹ï¼ˆæ–‡æœ¬æ–‡ä»¶çš„å‰å‡ è¡Œç­‰ï¼‰
    metadata JSONB, -- å…¶ä»–å…ƒæ•°æ®ï¼ˆå°ºå¯¸ã€ç¼–ç ç­‰ï¼‰
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ–‡ä»¶å…³è”è¡¨ï¼ˆæ–‡ä»¶ä¸å¯¹è¯æ¶ˆæ¯çš„å…³ç³»ï¼‰
CREATE TABLE file_message_relations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    file_id UUID REFERENCES files(id) ON DELETE CASCADE,
    message_id VARCHAR(255) NOT NULL, -- MongoDBä¸­çš„æ¶ˆæ¯ID
    relation_type VARCHAR(50) NOT NULL, -- 'input', 'output', 'attachment'
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### MongoDB Collectionsï¼ˆéç»“æ„åŒ–æ•°æ®ï¼‰

```javascript
// å¯¹è¯é›†åˆ
conversations: {
  _id: ObjectId,
  user_id: String,
  session_id: String,
  agent_type: String, // 'buyer', 'supplier', 'market'
  messages: [
    {
      message_id: String, // æ¶ˆæ¯å”¯ä¸€ID
      role: String, // 'user', 'assistant'
      content: String,
      timestamp: Date,
      files: [
        {
          file_id: String, // PostgreSQLä¸­çš„æ–‡ä»¶ID
          filename: String,
          file_type: String,
          relation_type: String // 'input', 'output', 'attachment'
        }
      ],
      metadata: {
        tokens: Number,
        model: String,
        tools_used: Array
      }
    }
  ],
  context: {
    user_profile: Object,
    product_info: Object,
    preferences: Object
  },
  files_summary: {
    total_files: Number,
    file_types: Array, // å¯¹è¯ä¸­æ¶‰åŠçš„æ–‡ä»¶ç±»å‹ç»Ÿè®¡
    generated_files: Number // Agentç”Ÿæˆçš„æ–‡ä»¶æ•°é‡
  },
  created_at: Date,
  updated_at: Date
}

// Agentä¼šè¯çŠ¶æ€
agent_sessions: {
  _id: ObjectId,
  session_id: String,
  user_id: String,
  agent_type: String,
  state: Object, // Agentçš„å†…éƒ¨çŠ¶æ€
  memory: Array, // çŸ­æœŸè®°å¿†
  last_activity: Date,
  expires_at: Date
}

// AIæ¨èç»“æœ
recommendations: {
  _id: ObjectId,
  user_id: String,
  type: String, // 'buyer', 'supplier'
  query: Object,
  results: [
    {
      name: String,
      score: Number,
      details: Object,
      contact_info: Object,
      reasoning: String
    }
  ],
  metadata: {
    processing_time: Number,
    data_sources: Array,
    confidence_score: Number
  },
  created_at: Date
}

// ç”¨æˆ·åé¦ˆ
user_feedback: {
  _id: ObjectId,
  user_id: String,
  reference_id: String, // å…³è”çš„æ¨èæˆ–å¯¹è¯ID
  type: String, // 'recommendation', 'conversation'
  rating: Number,
  comment: String,
  created_at: Date
}
```

### Redisç¼“å­˜ç»“æ„

```
# ç”¨æˆ·ä¼šè¯
session:{user_id} -> {
  token: JWT,
  user_data: {...},
  expires_at: timestamp
}

# APIé™æµ
rate_limit:{user_id}:{endpoint} -> count

# çƒ­ç‚¹æ•°æ®ç¼“å­˜
cache:products:{category} -> [products...]
cache:buyers:{market} -> [buyers...]

# Agentå¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆä¸´æ—¶ï¼‰
agent_context:{session_id} -> {
  messages: [...],
  state: {...}
}

# æ–‡ä»¶é¢„è§ˆç¼“å­˜
file_preview:{file_id} -> {
  content: preview_text,
  cached_at: timestamp
}
```

### MinIOå­˜å‚¨ç»“æ„

```
# Bucketç»„ç»‡ç»“æ„
tradeflow-files/
â”œâ”€â”€ users/{user_id}/
â”‚   â”œâ”€â”€ uploads/           # ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ documents/     # æ–‡æ¡£ç±»æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ images/        # å›¾ç‰‡æ–‡ä»¶
â”‚   â”‚   â””â”€â”€ data/          # æ•°æ®æ–‡ä»¶
â”‚   â””â”€â”€ generated/         # Agentç”Ÿæˆçš„æ–‡ä»¶
â”‚       â”œâ”€â”€ reports/       # ç”Ÿæˆçš„æŠ¥å‘Š
â”‚       â”œâ”€â”€ code/          # ç”Ÿæˆçš„ä»£ç æ–‡ä»¶
â”‚       â”œâ”€â”€ templates/     # ç”Ÿæˆçš„æ¨¡æ¿
â”‚       â””â”€â”€ analysis/      # åˆ†æç»“æœæ–‡ä»¶

# å¯¹è±¡é”®æ ¼å¼
{user_id}/{category}/{yyyy/mm/dd}/{uuid}.{extension}

# ç¤ºä¾‹
users/123e4567-e89b-12d3-a456-426614174000/
  uploads/documents/2024/01/15/contract_abc123.pdf
  generated/reports/2024/01/15/market_analysis_def456.docx
  generated/code/2024/01/15/api_client_ghi789.py

# ä¸´æ—¶æ–‡ä»¶å­˜å‚¨
temp-files/
â”œâ”€â”€ processing/{uuid}/     # æ–‡ä»¶å¤„ç†ä¸­çš„ä¸´æ—¶å­˜å‚¨
â””â”€â”€ preview/{file_id}/     # é¢„è§ˆå›¾ç¼“å­˜
```

---

## APIè®¾è®¡

### RESTful APIç«¯ç‚¹

#### è®¤è¯ç›¸å…³
```
POST   /api/v1/auth/oauth/{provider}     # OAuthç™»å½•
POST   /api/v1/auth/refresh              # åˆ·æ–°Token
POST   /api/v1/auth/logout               # ç™»å‡º
GET    /api/v1/auth/me                   # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
```

#### Agentå¯¹è¯
```
POST   /api/v1/chat                      # ç»Ÿä¸€å¯¹è¯å…¥å£
GET    /api/v1/chat/history              # è·å–å¯¹è¯å†å²
DELETE /api/v1/chat/session/{id}         # åˆ é™¤ä¼šè¯
```

#### ä¸šåŠ¡åŠŸèƒ½
```
# ä¹°å®¶å¼€å‘
POST   /api/v1/buyers/recommend          # è·å–ä¹°å®¶æ¨è
GET    /api/v1/buyers/{id}               # è·å–ä¹°å®¶è¯¦æƒ…
POST   /api/v1/buyers/{id}/contact       # ç”Ÿæˆè”ç³»æ¨¡æ¿

# ä¾›åº”å•†åŒ¹é…
POST   /api/v1/suppliers/search          # æœç´¢ä¾›åº”å•†
GET    /api/v1/suppliers/{id}            # è·å–ä¾›åº”å•†è¯¦æƒ…
POST   /api/v1/suppliers/compare         # ä¾›åº”å•†å¯¹æ¯”

# äº§å“ç®¡ç†
POST   /api/v1/products                  # åˆ›å»ºäº§å“
GET    /api/v1/products                  # è·å–äº§å“åˆ—è¡¨
PUT    /api/v1/products/{id}             # æ›´æ–°äº§å“
DELETE /api/v1/products/{id}             # åˆ é™¤äº§å“
```

#### æ–‡ä»¶ç®¡ç†
```
# æ–‡ä»¶ä¸Šä¼ å’Œç®¡ç†
POST   /api/v1/files/upload              # ä¸Šä¼ æ–‡ä»¶
GET    /api/v1/files/{id}                # è·å–æ–‡ä»¶å…ƒæ•°æ®
GET    /api/v1/files/{id}/download       # ä¸‹è½½æ–‡ä»¶
GET    /api/v1/files/{id}/preview        # è·å–æ–‡ä»¶é¢„è§ˆ
DELETE /api/v1/files/{id}                # åˆ é™¤æ–‡ä»¶
PUT    /api/v1/files/{id}                # æ›´æ–°æ–‡ä»¶å…ƒæ•°æ®

# å¯¹è¯æ–‡ä»¶å…³è”
GET    /api/v1/conversations/{id}/files  # è·å–å¯¹è¯å…³è”çš„æ‰€æœ‰æ–‡ä»¶
POST   /api/v1/conversations/{id}/files  # ä¸ºå¯¹è¯æ·»åŠ æ–‡ä»¶
DELETE /api/v1/conversations/{id}/files/{file_id} # ç§»é™¤å¯¹è¯æ–‡ä»¶å…³è”

# æ–‡ä»¶æœç´¢å’Œè¿‡æ»¤
GET    /api/v1/files                     # è·å–ç”¨æˆ·æ–‡ä»¶åˆ—è¡¨ï¼ˆæ”¯æŒåˆ†é¡µå’Œè¿‡æ»¤ï¼‰
GET    /api/v1/files/search              # æŒ‰æ–‡ä»¶åã€ç±»å‹ã€æ ‡ç­¾æœç´¢æ–‡ä»¶

# æ‰¹é‡æ“ä½œ
POST   /api/v1/files/batch/delete        # æ‰¹é‡åˆ é™¤æ–‡ä»¶
POST   /api/v1/files/batch/move          # æ‰¹é‡ç§»åŠ¨æ–‡ä»¶
POST   /api/v1/files/batch/tag           # æ‰¹é‡æ·»åŠ æ ‡ç­¾
```

#### è®¢é˜…å’Œæ”¯ä»˜
```
GET    /api/v1/subscription/plans        # è·å–è®¢é˜…è®¡åˆ’
POST   /api/v1/subscription/create       # åˆ›å»ºè®¢é˜…
POST   /api/v1/subscription/cancel       # å–æ¶ˆè®¢é˜…
GET    /api/v1/usage/summary             # ä½¿ç”¨ç»Ÿè®¡
```

### SSEï¼ˆServer-Sent Eventsï¼‰æ¥å£

#### æŠ€æœ¯é€‰æ‹©è¯´æ˜

**SSE vs WebSocketå¯¹æ¯”**ï¼š

| ç‰¹æ€§ | SSE | WebSocket |
|-----|-----|-----------|
| é€šä¿¡æ–¹å‘ | å•å‘ï¼ˆæœåŠ¡å™¨â†’å®¢æˆ·ç«¯ï¼‰ | åŒå‘ |
| åè®®å¤æ‚åº¦ | ç®€å•ï¼ˆåŸºäºHTTPï¼‰ | å¤æ‚ï¼ˆç‹¬ç«‹åè®®ï¼‰ |
| æµè§ˆå™¨æ”¯æŒ | åŸç”Ÿæ”¯æŒ | éœ€è¦é¢å¤–å¤„ç† |
| è‡ªåŠ¨é‡è¿ | å†…ç½® | éœ€è¦æ‰‹åŠ¨å®ç° |
| ä»£ç†å‹å¥½ | æ˜¯ | å¯èƒ½æœ‰é—®é¢˜ |
| å¹¶å‘è¿æ¥é™åˆ¶ | 6ä¸ª/åŸŸå | æ— é™åˆ¶ |

å¯¹äºTradeFlowè¿™ç§ä¸»è¦æ˜¯AIæµå¼å“åº”çš„åœºæ™¯ï¼ŒSSEæ›´åŠ ç®€å•å¯é ã€‚

#### æ¥å£å®šä¹‰

```javascript
// SSEè¿æ¥
GET /api/v1/chat/stream?token={jwt_token}

// å‘èµ·å¯¹è¯ï¼ˆHTTP POSTï¼‰
POST /api/v1/chat
{
  "message": "æ‰¾ç¾å›½çš„LEDç¯å…·ä¹°å®¶",
  "agent_type": "buyer",
  "session_id": "xxx",
  "stream": true
}

// SSE äº‹ä»¶æµæ ¼å¼
// æµå¼å†…å®¹
event: stream
data: {"chunk": "æ ¹æ®æ‚¨çš„éœ€æ±‚ï¼Œæˆ‘ä¸ºæ‚¨æ‰¾åˆ°äº†..."}

// æ¨èç»“æœ
event: recommendation
data: {"type": "buyer", "company": "Bright Lighting Inc.", "score": 0.92}

// å®Œæˆäº‹ä»¶
event: complete
data: {"session_id": "xxx", "tokens_used": 150, "total_recommendations": 5}

// é”™è¯¯äº‹ä»¶
event: error
data: {"error": "Agent processing failed", "code": "AGENT_ERROR"}
```

#### é‡è¦æŠ€æœ¯æ³¨æ„äº‹é¡¹

1. **æµè§ˆå™¨è¿æ¥é™åˆ¶**ï¼šåŒåŸŸåä¸‹æœ€å¤š6ä¸ªå¹¶å‘SSEè¿æ¥ï¼Œè¶…å‡ºéœ€è¦æ’é˜Ÿ
2. **è¿æ¥ç®¡ç†**ï¼šåŠæ—¶å…³é—­ä¸éœ€è¦çš„è¿æ¥ï¼Œé¿å…èµ„æºæµªè´¹
3. **é”™è¯¯å¤„ç†**ï¼šå®ç°å®¢æˆ·ç«¯è‡ªåŠ¨é‡è¿æœºåˆ¶
4. **CORSé…ç½®**ï¼šç¡®ä¿è·¨åŸŸè¯·æ±‚æ­£ç¡®é…ç½®
5. **ä»£ç†å…¼å®¹**ï¼šæŸäº›ä»£ç†å¯èƒ½ç¼“å†²SSEå“åº”ï¼Œå½±å“å®æ—¶æ€§

### APIè¯·æ±‚/å“åº”ç¤ºä¾‹

#### ä¹°å®¶æ¨èè¯·æ±‚
```json
POST /api/v1/buyers/recommend
{
  "product_info": {
    "name": "LED Panel Light",
    "category": "lighting",
    "description": "é«˜æ•ˆèŠ‚èƒ½LEDé¢æ¿ç¯",
    "price_range": "$10-50",
    "moq": 500
  },
  "target_markets": ["US", "DE", "UK"],
  "preferences": {
    "company_size": "medium",
    "trade_terms": "FOB"
  }
}
```

#### ä¹°å®¶æ¨èå“åº”
```json
{
  "status": "success",
  "data": {
    "recommendations": [
      {
        "company_name": "Bright Lighting Inc.",
        "country": "US",
        "match_score": 0.92,
        "buyer_profile": {
          "annual_purchase": "$2M+",
          "main_products": ["LED lights", "Smart lighting"],
          "company_size": "50-200"
        },
        "contact_suggestion": {
          "best_approach": "email",
          "template": "..."
        }
      }
    ],
    "total": 10,
    "query_id": "rec_123456"
  }
}
```

#### æ–‡ä»¶ä¸Šä¼ è¯·æ±‚
```json
POST /api/v1/files/upload
Content-Type: multipart/form-data

{
  "file": [binary_data],
  "conversation_id": "conv_123456",
  "description": "äº§å“è§„æ ¼ä¹¦",
  "tags": ["product", "specification"],
  "is_generated": false
}
```

#### æ–‡ä»¶ä¸Šä¼ å“åº”
```json
{
  "status": "success",
  "data": {
    "file": {
      "id": "file_789abc",
      "filename": "product_spec_1642567890.pdf",
      "original_filename": "äº§å“è§„æ ¼ä¹¦.pdf",
      "file_type": "document",
      "file_size": 2048576,
      "content_type": "application/pdf",
      "download_url": "/api/v1/files/file_789abc/download",
      "preview_url": "/api/v1/files/file_789abc/preview",
      "created_at": "2024-01-19T08:30:00Z"
    }
  }
}
```

#### è·å–å¯¹è¯æ–‡ä»¶åˆ—è¡¨è¯·æ±‚
```json
GET /api/v1/conversations/conv_123456/files?type=document&limit=10&offset=0
```

#### è·å–å¯¹è¯æ–‡ä»¶åˆ—è¡¨å“åº”
```json
{
  "status": "success",
  "data": {
    "files": [
      {
        "id": "file_789abc",
        "filename": "market_analysis_report.docx",
        "file_type": "document",
        "file_size": 1024000,
        "is_generated": true,
        "relation_type": "output",
        "preview_content": "# å¸‚åœºåˆ†ææŠ¥å‘Š\n\n## æ¦‚è¿°\næœ¬æŠ¥å‘Šåˆ†æäº†LEDç…§æ˜å¸‚åœº...",
        "created_at": "2024-01-19T08:30:00Z"
      },
      {
        "id": "file_def456",
        "filename": "buyer_contact_template.txt",
        "file_type": "code",
        "file_size": 2048,
        "is_generated": true,
        "relation_type": "output",
        "preview_content": "Dear [Company Name],\n\nWe are pleased to introduce...",
        "created_at": "2024-01-19T08:25:00Z"
      }
    ],
    "total": 15,
    "pagination": {
      "limit": 10,
      "offset": 0,
      "has_more": true
    }
  }
}
```

#### æ–‡ä»¶é¢„è§ˆè¯·æ±‚
```json
GET /api/v1/files/file_789abc/preview?lines=50&format=text
```

#### æ–‡ä»¶é¢„è§ˆå“åº”
```json
{
  "status": "success",
  "data": {
    "preview": {
      "content": "# LEDäº§å“è§„æ ¼ä¹¦\n\n## åŸºæœ¬å‚æ•°\n- åŠŸç‡: 12W\n- è‰²æ¸©: 4000K\n- æµæ˜: 1200lm...",
      "format": "markdown",
      "total_lines": 156,
      "preview_lines": 50,
      "file_info": {
        "filename": "product_spec.md",
        "file_size": 8192,
        "last_modified": "2024-01-19T08:30:00Z"
      }
    }
  }
}
```

---

## æ–‡ä»¶é¢„è§ˆç³»ç»Ÿè®¾è®¡

### ç³»ç»Ÿæ¦‚è¿°

æ–‡ä»¶é¢„è§ˆç³»ç»Ÿæ˜¯å¯¹è¯å†…å®¹å±•ç¤ºçš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œç”¨äºåœ¨å³ä¾§é¢æ¿ä¸­é¢„è§ˆå’Œç®¡ç†å¯¹è¯è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å„ç§æ–‡ä»¶ã€‚ç³»ç»Ÿæ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼çš„é¢„è§ˆï¼Œæä¾›ç›´è§‚çš„æ–‡ä»¶ç®¡ç†ç•Œé¢ã€‚

### æ”¯æŒçš„æ–‡ä»¶ç±»å‹

#### ä»£ç æ–‡ä»¶
- **.js, .ts, .jsx, .tsx**: JavaScript/TypeScriptæ–‡ä»¶ï¼Œæ”¯æŒè¯­æ³•é«˜äº®
- **.py**: Pythonæ–‡ä»¶ï¼Œæ”¯æŒè¯­æ³•é«˜äº®å’Œä»£ç æŠ˜å 
- **.json**: JSONæ–‡ä»¶ï¼Œæ”¯æŒæ ¼å¼åŒ–æ˜¾ç¤ºå’Œè¯­æ³•éªŒè¯
- **.yaml, .yml**: YAMLé…ç½®æ–‡ä»¶
- **.sql**: SQLè„šæœ¬æ–‡ä»¶

#### æ–‡æ¡£æ–‡ä»¶
- **.md**: Markdownæ–‡ä»¶ï¼Œæ”¯æŒæ¸²æŸ“é¢„è§ˆå’Œæºç æŸ¥çœ‹
- **.txt**: çº¯æ–‡æœ¬æ–‡ä»¶
- **.pdf**: PDFæ–‡æ¡£ï¼Œæ”¯æŒåˆ†é¡µé¢„è§ˆ
- **.docx**: Wordæ–‡æ¡£ï¼Œè½¬æ¢ä¸ºHTMLé¢„è§ˆ
- **.html**: HTMLæ–‡ä»¶ï¼Œæ”¯æŒæ¸²æŸ“å’Œæºç æ¨¡å¼

#### æ•°æ®æ–‡ä»¶
- **.csv**: CSVæ•°æ®æ–‡ä»¶ï¼Œæ”¯æŒè¡¨æ ¼å½¢å¼å±•ç¤º
- **.xlsx**: Excelæ–‡ä»¶ï¼Œæ”¯æŒå·¥ä½œè¡¨åˆ‡æ¢
- **.json**: JSONæ•°æ®æ–‡ä»¶ï¼Œæ”¯æŒæ ‘å½¢ç»“æ„å±•ç¤º

#### å›¾åƒæ–‡ä»¶
- **.png, .jpg, .jpeg**: ä½å›¾å›¾åƒï¼Œæ”¯æŒç¼©æ”¾å’Œå…¨å±æŸ¥çœ‹
- **.svg**: çŸ¢é‡å›¾åƒï¼Œæ”¯æŒä»£ç æŸ¥çœ‹å’Œæ¸²æŸ“é¢„è§ˆ
- **.webp**: ç°ä»£å›¾åƒæ ¼å¼

### æ¶æ„è®¾è®¡

#### æ–‡ä»¶å¤„ç†æµç¨‹

```mermaid
graph TD
    A[Agentç”Ÿæˆæ–‡ä»¶] --> B[æ–‡ä»¶æœåŠ¡æ¥æ”¶]
    B --> C[æ–‡ä»¶ç±»å‹è¯†åˆ«]
    C --> D[å­˜å‚¨åˆ°MinIO]
    D --> E[å…ƒæ•°æ®å­˜å‚¨åˆ°PostgreSQL]
    E --> F[å…³è”åˆ°å¯¹è¯æ¶ˆæ¯]
    F --> G[ç”Ÿæˆé¢„è§ˆå†…å®¹]
    G --> H[ç¼“å­˜é¢„è§ˆåˆ°Redis]
    H --> I[é€šçŸ¥å‰ç«¯æ›´æ–°]
    
    J[ç”¨æˆ·ç‚¹å‡»æ–‡ä»¶] --> K[æ£€æŸ¥é¢„è§ˆç¼“å­˜]
    K --> L{ç¼“å­˜å­˜åœ¨?}
    L -->|æ˜¯| M[è¿”å›ç¼“å­˜å†…å®¹]
    L -->|å¦| N[ä»MinIOè¯»å–æ–‡ä»¶]
    N --> O[ç”Ÿæˆé¢„è§ˆå†…å®¹]
    O --> P[æ›´æ–°ç¼“å­˜]
    P --> M
```

#### å‰ç«¯ç»„ä»¶æ¶æ„

```typescript
// æ–‡ä»¶é¢„è§ˆé¢æ¿ç»„ä»¶ç»“æ„
interface FilePreviewPanel {
  // æ–‡ä»¶åˆ—è¡¨ç»„ä»¶
  FileList: {
    filters: FileFilter[];
    sortOptions: SortOption[];
    files: FileInfo[];
  };
  
  // é¢„è§ˆç»„ä»¶
  FilePreview: {
    currentFile: FileInfo | null;
    previewMode: 'code' | 'rendered' | 'image' | 'table';
    renderComponent: CodePreview | ImagePreview | TablePreview | DocumentPreview;
  };
  
  // æ“ä½œå·¥å…·æ 
  FileToolbar: {
    actions: ['download', 'copy', 'share', 'delete'];
    viewOptions: ['fullscreen', 'split', 'panel'];
  };
}
```

### é¢„è§ˆå®ç°æ–¹æ¡ˆ

#### ä»£ç æ–‡ä»¶é¢„è§ˆ
```typescript
// ä½¿ç”¨react-syntax-highlighterè¿›è¡Œè¯­æ³•é«˜äº®
import { Prism as SyntaxHighlighter } from 'react-syntax-highlighter';
import { vscDarkPlus } from 'react-syntax-highlighter/dist/esm/styles/prism';

const CodePreview: React.FC<{ content: string; language: string }> = ({ content, language }) => {
  return (
    <SyntaxHighlighter 
      language={language}
      style={vscDarkPlus}
      showLineNumbers={true}
      wrapLines={true}
    >
      {content}
    </SyntaxHighlighter>
  );
};
```

#### Markdownæ–‡ä»¶é¢„è§ˆ
```typescript
// ä½¿ç”¨react-markdownè¿›è¡Œæ¸²æŸ“
import ReactMarkdown from 'react-markdown';
import remarkGfm from 'remark-gfm';
import { Prism as SyntaxHighlighter } from 'react-syntax-highlighter';

const MarkdownPreview: React.FC<{ content: string }> = ({ content }) => {
  return (
    <ReactMarkdown
      remarkPlugins={[remarkGfm]}
      components={{
        code: ({ node, inline, className, children, ...props }) => {
          const match = /language-(\w+)/.exec(className || '');
          return !inline && match ? (
            <SyntaxHighlighter language={match[1]} {...props}>
              {String(children).replace(/\n$/, '')}
            </SyntaxHighlighter>
          ) : (
            <code className={className} {...props}>
              {children}
            </code>
          );
        }
      }}
    >
      {content}
    </ReactMarkdown>
  );
};
```

#### CSVæ•°æ®é¢„è§ˆ
```typescript
// ä½¿ç”¨react-tableè¿›è¡Œè¡¨æ ¼å±•ç¤º
import { useTable, usePagination } from 'react-table';

const CSVPreview: React.FC<{ data: any[]; columns: any[] }> = ({ data, columns }) => {
  const {
    getTableProps,
    getTableBodyProps,
    headerGroups,
    page,
    prepareRow,
    canPreviousPage,
    canNextPage,
    nextPage,
    previousPage,
    pageCount,
    state: { pageIndex }
  } = useTable({ columns, data }, usePagination);

  return (
    <div>
      <table {...getTableProps()}>
        <thead>
          {headerGroups.map(headerGroup => (
            <tr {...headerGroup.getHeaderGroupProps()}>
              {headerGroup.headers.map(column => (
                <th {...column.getHeaderProps()}>
                  {column.render('Header')}
                </th>
              ))}
            </tr>
          ))}
        </thead>
        <tbody {...getTableBodyProps()}>
          {page.map(row => {
            prepareRow(row);
            return (
              <tr {...row.getRowProps()}>
                {row.cells.map(cell => (
                  <td {...cell.getCellProps()}>
                    {cell.render('Cell')}
                  </td>
                ))}
              </tr>
            );
          })}
        </tbody>
      </table>
      {/* åˆ†é¡µæ§ä»¶ */}
      <div>
        <button onClick={() => previousPage()} disabled={!canPreviousPage}>
          ä¸Šä¸€é¡µ
        </button>
        <span>
          ç¬¬ {pageIndex + 1} é¡µï¼Œå…± {pageCount} é¡µ
        </span>
        <button onClick={() => nextPage()} disabled={!canNextPage}>
          ä¸‹ä¸€é¡µ
        </button>
      </div>
    </div>
  );
};
```

### åç«¯æ–‡ä»¶æœåŠ¡å®ç°

#### æ–‡ä»¶æœåŠ¡ç±»è®¾è®¡

```python
# src/backend/services/file_service.py
from typing import List, Optional, BinaryIO
import minio
from minio import Minio
import uuid
import os
from datetime import datetime
import magic

class FileService:
    """æ–‡ä»¶ç®¡ç†æœåŠ¡"""
    
    def __init__(self, minio_client: Minio, db_session):
        self.minio_client = minio_client
        self.db_session = db_session
        self.bucket_name = "tradeflow-files"
    
    async def upload_file(
        self,
        file: BinaryIO,
        user_id: str,
        conversation_id: str = None,
        original_filename: str = None,
        description: str = None,
        tags: List[str] = None
    ) -> dict:
        """ä¸Šä¼ æ–‡ä»¶å¹¶è¿”å›æ–‡ä»¶ä¿¡æ¯"""
        
        # ç”Ÿæˆæ–‡ä»¶IDå’Œå­˜å‚¨è·¯å¾„
        file_id = str(uuid.uuid4())
        file_content = file.read()
        file_size = len(file_content)
        
        # æ£€æµ‹æ–‡ä»¶ç±»å‹
        content_type = magic.from_buffer(file_content, mime=True)
        file_extension = self._get_file_extension(original_filename or "")
        file_type = self._classify_file_type(content_type, file_extension)
        
        # ç”ŸæˆMinIOå¯¹è±¡é”®
        today = datetime.now()
        category = "generated" if conversation_id else "uploads"
        object_key = f"users/{user_id}/{category}/{file_type}s/{today.strftime('%Y/%m/%d')}/{file_id}{file_extension}"
        
        # ä¸Šä¼ åˆ°MinIO
        self.minio_client.put_object(
            bucket_name=self.bucket_name,
            object_name=object_key,
            data=BytesIO(file_content),
            length=file_size,
            content_type=content_type
        )
        
        # ç”Ÿæˆé¢„è§ˆå†…å®¹
        preview_content = await self._generate_preview(
            file_content, file_type, file_extension
        )
        
        # ä¿å­˜å…ƒæ•°æ®åˆ°æ•°æ®åº“
        file_record = FileRecord(
            id=file_id,
            user_id=user_id,
            conversation_id=conversation_id,
            filename=f"{original_filename}_{int(datetime.now().timestamp())}{file_extension}",
            original_filename=original_filename,
            file_type=file_type,
            file_extension=file_extension,
            content_type=content_type,
            file_size=file_size,
            minio_bucket=self.bucket_name,
            minio_object_key=object_key,
            description=description,
            tags=tags or [],
            preview_content=preview_content[:1000] if preview_content else None  # é™åˆ¶é¢„è§ˆé•¿åº¦
        )
        
        self.db_session.add(file_record)
        await self.db_session.commit()
        
        return {
            "id": file_id,
            "filename": file_record.filename,
            "file_type": file_type,
            "file_size": file_size,
            "content_type": content_type,
            "download_url": f"/api/v1/files/{file_id}/download",
            "preview_url": f"/api/v1/files/{file_id}/preview",
            "created_at": file_record.created_at
        }
    
    async def get_file_preview(
        self, 
        file_id: str, 
        lines: int = None,
        format: str = "auto"
    ) -> dict:
        """è·å–æ–‡ä»¶é¢„è§ˆå†…å®¹"""
        
        # ä»ç¼“å­˜æ£€æŸ¥
        cache_key = f"file_preview:{file_id}:{lines}:{format}"
        cached_content = await redis_client.get(cache_key)
        if cached_content:
            return json.loads(cached_content)
        
        # ä»æ•°æ®åº“è·å–æ–‡ä»¶ä¿¡æ¯
        file_record = await self.db_session.get(FileRecord, file_id)
        if not file_record:
            raise FileNotFoundError(f"File {file_id} not found")
        
        # ä»MinIOè·å–æ–‡ä»¶å†…å®¹
        response = self.minio_client.get_object(
            bucket_name=file_record.minio_bucket,
            object_name=file_record.minio_object_key
        )
        content = response.data
        
        # ç”Ÿæˆé¢„è§ˆ
        preview_content = await self._generate_preview(
            content, 
            file_record.file_type, 
            file_record.file_extension,
            lines
        )
        
        result = {
            "content": preview_content,
            "format": self._detect_preview_format(file_record.file_extension),
            "file_info": {
                "filename": file_record.filename,
                "file_size": file_record.file_size,
                "file_type": file_record.file_type,
                "last_modified": file_record.updated_at
            }
        }
        
        # ç¼“å­˜é¢„è§ˆå†…å®¹ï¼ˆ1å°æ—¶ï¼‰
        await redis_client.setex(cache_key, 3600, json.dumps(result))
        
        return result
    
    def _classify_file_type(self, content_type: str, extension: str) -> str:
        """æ ¹æ®MIMEç±»å‹å’Œæ‰©å±•ååˆ†ç±»æ–‡ä»¶"""
        if extension in ['.py', '.js', '.ts', '.jsx', '.tsx', '.json', '.sql', '.yaml', '.yml']:
            return 'code'
        elif extension in ['.md', '.txt', '.pdf', '.docx', '.html']:
            return 'document'
        elif extension in ['.csv', '.xlsx']:
            return 'data'
        elif content_type.startswith('image/'):
            return 'image'
        else:
            return 'document'
    
    async def _generate_preview(
        self, 
        content: bytes, 
        file_type: str, 
        extension: str,
        lines: int = 50
    ) -> str:
        """ç”Ÿæˆæ–‡ä»¶é¢„è§ˆå†…å®¹"""
        try:
            if file_type == 'image':
                return f"[å›¾åƒæ–‡ä»¶: {extension}]"
            
            # å°è¯•è§£ç ä¸ºæ–‡æœ¬
            text_content = content.decode('utf-8')
            
            if lines:
                text_lines = text_content.split('\n')[:lines]
                return '\n'.join(text_lines)
            
            # å¯¹äºå¤§æ–‡ä»¶ï¼Œåªè¿”å›å‰1000ä¸ªå­—ç¬¦
            if len(text_content) > 1000:
                return text_content[:1000] + "..."
            
            return text_content
            
        except UnicodeDecodeError:
            return f"[äºŒè¿›åˆ¶æ–‡ä»¶: {extension}]"
```

### æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

#### 1. é¢„è§ˆå†…å®¹ç¼“å­˜
- ä½¿ç”¨Redisç¼“å­˜å¸¸ç”¨æ–‡ä»¶çš„é¢„è§ˆå†…å®¹
- æ”¯æŒæŒ‰æ–‡ä»¶ä¿®æ”¹æ—¶é—´è‡ªåŠ¨å¤±æ•ˆ
- å¤§æ–‡ä»¶é‡‡ç”¨åˆ†æ®µé¢„è§ˆå’Œå»¶è¿ŸåŠ è½½

#### 2. å›¾åƒä¼˜åŒ–
- è‡ªåŠ¨ç”Ÿæˆç¼©ç•¥å›¾
- æ”¯æŒWebPæ ¼å¼å‹ç¼©
- å®ç°æ¸è¿›å¼åŠ è½½

#### 3. å¤§æ–‡ä»¶å¤„ç†
- æ”¯æŒåˆ†å—ä¸Šä¼ å’Œä¸‹è½½
- å¤§æ–‡æœ¬æ–‡ä»¶é‡‡ç”¨è™šæ‹Ÿæ»šåŠ¨
- PDFæ–‡ä»¶æŒ‰é¡µé¢„è§ˆ

#### 4. å¸¦å®½ä¼˜åŒ–
- å®ç°æ–‡ä»¶å†…å®¹å‹ç¼©
- æ”¯æŒRangeè¯·æ±‚
- CDNåŠ é€Ÿé™æ€æ–‡ä»¶è®¿é—®

---

## Google ADK Agentå¼€å‘æ–¹æ¡ˆ ã€âœ… å·²å®ç°ã€‘

> **å®ç°çŠ¶æ€**: TradeFlowAgentå·²å®Œæ•´å®ç°ï¼Œé‡‡ç”¨å±‚æ¬¡åŒ–ReActæ¶æ„
> **ä»£ç ä½ç½®**: `src/agent/TradeFlowAgent/`
> **å¼€å‘çŠ¶æ€**: åŠŸèƒ½å®Œæ•´ï¼Œå·²é€šè¿‡æµ‹è¯•ï¼Œå¾…é›†æˆ

### å·²å®ç°çš„Agentæ¶æ„

#### å±‚æ¬¡åŒ–ReActæ¶æ„è®¾è®¡
```
TradeFlow Agent System
â”œâ”€â”€ ğŸ§  ç³»ç»Ÿçº§ReAct - ä¸»åè°ƒAgent
â”‚   â”œâ”€â”€ ä½¿ç”¨PlanReActPlannerè¿›è¡Œç³»ç»Ÿçº§æ¨ç†
â”‚   â”œâ”€â”€ åŠ¨æ€Agenté€‰æ‹©å’Œåè°ƒ
â”‚   â””â”€â”€ è´¨é‡è¯„ä¼°å’Œç­–ç•¥è°ƒæ•´
â”œâ”€â”€ ğŸ¯ ä¸“ä¸šçº§ReAct - ä¾›åº”å•†åˆ†æAgent  
â”‚   â”œâ”€â”€ ä¾›åº”å•†æ•°æ®èšåˆå’Œè¯„åˆ†
â”‚   â”œâ”€â”€ ä¾›åº”é“¾å…³ç³»åˆ†æ
â”‚   â””â”€â”€ åŒ¹é…æ¨èç®—æ³•
â””â”€â”€ âš¡ æ‰§è¡Œçº§å·¥å…· - 6ä¸ªä¸“ä¸šAgent
    â”œâ”€â”€ search_agent (Jina Search)
    â”œâ”€â”€ trade_agent (Tendata API)
    â”œâ”€â”€ company_agent (ä¼ä¸šä¿¡æ¯æŸ¥è¯¢)
    â”œâ”€â”€ enterprise_discovery_agent (B2Bå¹³å°æœç´¢)
    â”œâ”€â”€ web_analyzer_agent (Jina Reader)
    â””â”€â”€ state_manager_agent (ä¼šè¯çŠ¶æ€ç®¡ç†)
```

#### å®é™…å®ç°ä»£ç ç»“æ„
```python
# src/agent/TradeFlowAgent/trade_flow/main_agent.py
from google.adk.agents import Agent
from google.adk.planners import PlanReActPlanner

# åˆ›å»ºä¸»åè°ƒAgentï¼ˆç³»ç»Ÿçº§ReActï¼‰
root_agent = Agent(
    name="trade_flow_orchestrator",
    model=get_model_config(),
    planner=PlanReActPlanner(),  # ç³»ç»Ÿçº§æ¨ç†
    description="è´¸æ˜“æ•°æ®æŸ¥è¯¢å’Œåˆ†æçš„ä¸»åè°ƒå™¨",
    instruction="""ä½¿ç”¨ReActæ¨¡å¼è¿›è¡Œç³»ç»Ÿçº§æ¨ç†...""",
    agents=[search_agent, trade_agent, company_agent]
)
```

### å·²å®ç°çš„æ ¸å¿ƒå·¥å…·é›†

#### 1. æœç´¢åˆ†æå·¥å…·
- **web_search.py**: Jina Search APIé›†æˆï¼Œé«˜è´¨é‡ç½‘é¡µæœç´¢
- **jina_reader.py**: ç½‘é¡µå†…å®¹æå–ï¼Œæ”¯æŒå•†å“é¡µé¢è§£æ
- **enterprise_discovery.py**: B2Bå¹³å°ä¼ä¸šå‘ç°

#### 2. è´¸æ˜“æ•°æ®å·¥å…·
- **tendata_api.py**: æµ·å…³æ•°æ®æŸ¥è¯¢æ¥å£
- **trade_data_query.py**: è´¸æ˜“ç»Ÿè®¡åˆ†æ
- **company_trade_profile.py**: ä¼ä¸šè´¸æ˜“ç”»åƒç”Ÿæˆ

#### 3. ä¼ä¸šä¿¡æ¯å·¥å…·
- **company_info.py**: ä¼ä¸šèµ„è´¨æŸ¥è¯¢
- **company_query.py**: ä¼ä¸šèƒŒæ™¯è°ƒæŸ¥
- **supplier_profile.py**: ä¾›åº”å•†æ¡£æ¡ˆç®¡ç†

#### 4. æ–‡ä»¶å¤„ç†å·¥å…·
- **artifacts_manager.py**: æ–‡ä»¶ç”Ÿæˆç®¡ç†
- **csv_converter.py**: CSVæŠ¥å‘Šç”Ÿæˆ
- **download_artifact.py**: æ–‡ä»¶ä¸‹è½½æœåŠ¡

### å·²éªŒè¯çš„æ ¸å¿ƒåŠŸèƒ½

#### 1. å•†å“ä¾›åº”å•†å‘ç° âœ…
**è¾“å…¥ç¤ºä¾‹**: `"åˆ†æè¿™ä¸ªå•†å“çš„ä¾›åº”å•†ï¼šhttps://www.walmart.com/ip/Apple-iPhone-15"`
**è¾“å‡ºèƒ½åŠ›**:
- å®Œæ•´ä¾›åº”é“¾å±‚çº§ï¼šé›¶å”®å•†â†’å“ç‰Œæ–¹â†’ä»£å·¥å‚â†’åŸææ–™ä¾›åº”å•†
- å…·ä½“ä¼ä¸šä¿¡æ¯ï¼šå¯Œå£«åº·ã€æ¯”äºšè¿ªç”µå­ç­‰ä¸»è¦ä»£å·¥å‚
- è”ç³»æ–¹å¼ï¼šåŒ…å«ç”µè¯ã€é‚®ç®±ã€è”ç³»äººå§“å
- è´¸æ˜“æ•°æ®éªŒè¯ï¼šåŸºäºçœŸå®æµ·å…³å‡ºå£è®°å½•

#### 2. è´¸æ˜“æ•°æ®æŸ¥è¯¢ âœ…
**è¾“å…¥ç¤ºä¾‹**: `"æŸ¥è¯¢2024å¹´æ‰‹æœºå¯¹ç¾å›½çš„å‡ºå£æ•°æ®"`
**è¾“å‡ºèƒ½åŠ›**:
- å‡ºå£æ€»é¢å’Œè¶‹åŠ¿åˆ†æ
- ä¸»è¦å‡ºå£å›½å®¶å’Œä»½é¢
- çƒ­é—¨å“ç‰Œå’Œäº§å“åˆ†å¸ƒ
- å…³ç¨å’Œè´¸æ˜“æ”¿ç­–å½±å“

#### 3. ä¼ä¸šèƒŒæ™¯è°ƒæŸ¥ âœ…
**è¾“å…¥ç¤ºä¾‹**: `"åˆ†ææ¯”äºšè¿ªç”µå­çš„ä¾›åº”å•†èµ„è´¨"`
**è¾“å‡ºèƒ½åŠ›**:
- ä¼ä¸šèµ„è´¨è®¤è¯ï¼ˆISOã€è¡Œä¸šè®¤è¯ï¼‰
- è´¸æ˜“èƒ½åŠ›è¯„ä¼°ï¼ˆå¹´å‡ºå£é¢ã€è¦†ç›–å›½å®¶ï¼‰
- ä¸»è¦å®¢æˆ·å’Œäº§å“çº¿
- é£é™©è¯„ä¼°å’Œåˆä½œå»ºè®®

### Agentä¸åç«¯é›†æˆæ–¹æ¡ˆï¼ˆå¾…å®æ–½ï¼‰

```python
# è®¡åˆ’çš„é›†æˆæ¥å£
class AgentGatewayService:
    """Agentç½‘å…³æœåŠ¡ï¼Œè´Ÿè´£è°ƒåº¦TradeFlowAgent"""
    
    async def process_query(
        self, 
        query: str,
        user_id: int,
        session_id: str
    ) -> AsyncGenerator:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶è¿”å›æµå¼å“åº”"""
        # 1. è°ƒç”¨TradeFlowAgent
        # 2. é€šè¿‡SSEè¿”å›ç»“æœ
        # 3. ä¿å­˜å¯¹è¯å†å²åˆ°MongoDB
        pass
                "data_sources": ["trade_data", "company_db"]
            }
        }
```

### Agentå·¥å…·å®ç°

```python
# src/agent/tools/trade_data_tool.py
from google.adk.tools import BaseTool
from pydantic import BaseModel, Field
from typing import Dict, List
import asyncio

class TradeDataSearchParams(BaseModel):
    product_category: str = Field(description="äº§å“ç±»åˆ«")
    target_market: str = Field(description="ç›®æ ‡å¸‚åœº")
    trade_type: str = Field(description="è´¸æ˜“ç±»å‹ï¼šimport/export")

class TradeDataSearchTool(BaseTool):
    """è´¸æ˜“æ•°æ®æœç´¢å·¥å…·"""
    
    name = "trade_data_search"
    description = "æœç´¢å…¨çƒè´¸æ˜“æ•°æ®"
    parameters_model = TradeDataSearchParams
    
    async def run_async(
        self, 
        args: Dict, 
        tool_context: Any
    ) -> Dict:
        params = TradeDataSearchParams(**args)
        
        # æŸ¥è¯¢MongoDBä¸­çš„è´¸æ˜“æ•°æ®
        trade_data = await self._query_trade_db(
            category=params.product_category,
            market=params.target_market
        )
        
        return {
            "market_size": trade_data.get("market_size"),
            "growth_rate": trade_data.get("growth_rate"),
            "top_importers": trade_data.get("importers", [])[:10],
            "price_trends": trade_data.get("price_trends")
        }
```

### Agent GatewayæœåŠ¡

```python
# src/backend/services/agent_gateway.py
from typing import Dict, Optional
from enum import Enum
import asyncio

class AgentType(str, Enum):
    BUYER = "buyer"
    SUPPLIER = "supplier"
    MARKET = "market"

class AgentGatewayService:
    """Agentç½‘å…³æœåŠ¡"""
    
    def __init__(self):
        self.agents = {
            AgentType.BUYER: BuyerDevelopmentAgent(),
            AgentType.SUPPLIER: SupplierMatchingAgent(),
            AgentType.MARKET: MarketAnalysisAgent()
        }
        self.intent_classifier = IntentClassifier()
    
    async def route_request(
        self,
        message: str,
        agent_type: Optional[AgentType],
        context: Dict,
        user_id: str
    ) -> Dict:
        """è·¯ç”±è¯·æ±‚åˆ°åˆé€‚çš„Agent"""
        
        # è‡ªåŠ¨è¯†åˆ«Agentç±»å‹
        if not agent_type:
            agent_type = await self.intent_classifier.classify(
                message, context
            )
        
        # è·å–Agent
        agent = self.agents.get(agent_type)
        if not agent:
            raise ValueError(f"Unknown agent type: {agent_type}")
        
        # å¤„ç†è¯·æ±‚
        try:
            # ä»MongoDBåŠ è½½ä¼šè¯ä¸Šä¸‹æ–‡
            session_context = await self._load_session_context(
                user_id, agent_type
            )
            
            # åˆå¹¶ä¸Šä¸‹æ–‡
            full_context = {
                **session_context,
                **context,
                "user_id": user_id
            }
            
            # è°ƒç”¨Agent
            response = await agent.process(message, full_context)
            
            # ä¿å­˜å¯¹è¯åˆ°MongoDB
            await self._save_conversation(
                user_id, agent_type, message, response
            )
            
            return response
            
        except Exception as e:
            logger.error(f"Agent error: {str(e)}")
            raise
```

---

## MinIOå¯¹è±¡å­˜å‚¨é›†æˆæ–¹æ¡ˆ

### MinIOé€‰æ‹©ç†ç”±

ç›¸æ¯”äºè®¾è®¡å¸ˆå»ºè®®çš„Google Cloud Storageï¼Œæˆ‘ä»¬é€‰æ‹©MinIOä½œä¸ºå¯¹è±¡å­˜å‚¨æ–¹æ¡ˆçš„åŸå› ï¼š

1. **è‡ªä¸»å¯æ§**: MinIOæ˜¯å¼€æºè§£å†³æ–¹æ¡ˆï¼Œé¿å…äº‘æœåŠ¡vendor lock-in
2. **æˆæœ¬ä¼˜åŠ¿**: è‡ªæ‰˜ç®¡MinIOæˆæœ¬æ›´ä½ï¼Œç‰¹åˆ«æ˜¯åœ¨MVPé˜¶æ®µ
3. **éƒ¨ç½²çµæ´»**: æ”¯æŒæœ¬åœ°å¼€å‘ã€ç§æœ‰äº‘å’Œå…¬æœ‰äº‘å¤šç§éƒ¨ç½²æ–¹å¼
4. **S3å…¼å®¹**: å®Œå…¨å…¼å®¹Amazon S3 APIï¼Œä¾¿äºåç»­è¿ç§»
5. **é«˜æ€§èƒ½**: ä¸“ä¸ºäº‘åŸç”Ÿç¯å¢ƒä¼˜åŒ–ï¼Œæ€§èƒ½è¡¨ç°ä¼˜å¼‚

### MinIOæ¶æ„è®¾è®¡

#### æœåŠ¡é…ç½®

```yaml
# minio-config.yaml
version: '3.8'
services:
  minio:
    image: minio/minio:latest
    container_name: tradeflow-minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio-data:/data
    environment:
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
      MINIO_BROWSER_REDIRECT_URL: http://localhost:9001
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

volumes:
  minio-data:
    driver: local
```

#### å®¢æˆ·ç«¯é›†æˆ

```python
# src/backend/config/minio_config.py
from minio import Minio
from pydantic import BaseSettings
import logging

class MinIOConfig(BaseSettings):
    """MinIOé…ç½®ç±»"""
    
    MINIO_ENDPOINT: str = "localhost:9000"
    MINIO_ACCESS_KEY: str
    MINIO_SECRET_KEY: str
    MINIO_SECURE: bool = False  # å¼€å‘ç¯å¢ƒä½¿ç”¨HTTP
    MINIO_REGION: str = "us-east-1"
    
    # Bucketé…ç½®
    MINIO_BUCKET_FILES: str = "tradeflow-files"
    MINIO_BUCKET_TEMP: str = "tradeflow-temp"
    MINIO_BUCKET_BACKUPS: str = "tradeflow-backups"
    
    class Config:
        env_file = ".env"

class MinIOClient:
    """MinIOå®¢æˆ·ç«¯å•ä¾‹"""
    
    _instance = None
    _client = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(MinIOClient, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        if self._client is None:
            self.config = MinIOConfig()
            self._client = Minio(
                endpoint=self.config.MINIO_ENDPOINT,
                access_key=self.config.MINIO_ACCESS_KEY,
                secret_key=self.config.MINIO_SECRET_KEY,
                secure=self.config.MINIO_SECURE,
                region=self.config.MINIO_REGION
            )
            self._ensure_buckets_exist()
    
    def _ensure_buckets_exist(self):
        """ç¡®ä¿å¿…è¦çš„bucketå­˜åœ¨"""
        buckets = [
            self.config.MINIO_BUCKET_FILES,
            self.config.MINIO_BUCKET_TEMP,
            self.config.MINIO_BUCKET_BACKUPS
        ]
        
        for bucket in buckets:
            if not self._client.bucket_exists(bucket):
                self._client.make_bucket(bucket)
                
                # è®¾ç½®bucketç­–ç•¥
                if bucket == self.config.MINIO_BUCKET_FILES:
                    self._set_public_read_policy(bucket)
    
    def _set_public_read_policy(self, bucket_name: str):
        """è®¾ç½®bucketçš„å…¬å…±è¯»å–ç­–ç•¥"""
        policy = {
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Effect": "Allow",
                    "Principal": {"AWS": "*"},
                    "Action": ["s3:GetObject"],
                    "Resource": [f"arn:aws:s3:::{bucket_name}/*"]
                }
            ]
        }
        
        import json
        self._client.set_bucket_policy(
            bucket_name, 
            json.dumps(policy)
        )
    
    @property
    def client(self) -> Minio:
        return self._client

# å…¨å±€MinIOå®¢æˆ·ç«¯å®ä¾‹
minio_client = MinIOClient().client
```

### Agentæ–‡ä»¶ç”Ÿæˆé›†æˆ

#### Agentå·¥å…·æ‰©å±•

```python
# src/agent/tools/file_generation_tool.py
from google.adk.tools import BaseTool
from pydantic import BaseModel, Field
from typing import Dict, List, Any
import uuid
import io
from ..services.file_service import FileService

class FileGenerationParams(BaseModel):
    content: str = Field(description="æ–‡ä»¶å†…å®¹")
    filename: str = Field(description="æ–‡ä»¶å")
    file_type: str = Field(description="æ–‡ä»¶ç±»å‹: code/document/data")
    description: str = Field(description="æ–‡ä»¶æè¿°")

class FileGenerationTool(BaseTool):
    """Agentæ–‡ä»¶ç”Ÿæˆå·¥å…·"""
    
    name = "generate_file"
    description = "ç”Ÿæˆæ–‡ä»¶å¹¶ä¿å­˜åˆ°å­˜å‚¨ç³»ç»Ÿ"
    parameters_model = FileGenerationParams
    
    def __init__(self, file_service: FileService):
        super().__init__()
        self.file_service = file_service
    
    async def run_async(
        self, 
        args: Dict, 
        tool_context: Any
    ) -> Dict:
        """æ‰§è¡Œæ–‡ä»¶ç”Ÿæˆ"""
        params = FileGenerationParams(**args)
        
        # åˆ›å»ºæ–‡ä»¶å†…å®¹çš„å­—èŠ‚æµ
        file_content = io.BytesIO(params.content.encode('utf-8'))
        
        # ä»å·¥å…·ä¸Šä¸‹æ–‡è·å–ç”¨æˆ·å’Œå¯¹è¯ä¿¡æ¯
        user_id = tool_context.get("user_id")
        conversation_id = tool_context.get("conversation_id")
        
        # ä¸Šä¼ æ–‡ä»¶
        file_info = await self.file_service.upload_file(
            file=file_content,
            user_id=user_id,
            conversation_id=conversation_id,
            original_filename=params.filename,
            description=params.description,
            tags=[params.file_type, "agent_generated"]
        )
        
        return {
            "success": True,
            "file_id": file_info["id"],
            "filename": file_info["filename"],
            "download_url": file_info["download_url"],
            "preview_url": file_info["preview_url"],
            "message": f"æ–‡ä»¶ {params.filename} å·²ç”Ÿæˆå¹¶ä¿å­˜"
        }
```

#### Agenté›†æˆç¤ºä¾‹

```python
# src/agent/buyer_agent.py æ›´æ–°
class BuyerDevelopmentAgent(BaseTradeAgent):
    """ä¹°å®¶å¼€å‘Agent - é›†æˆæ–‡ä»¶ç”ŸæˆåŠŸèƒ½"""
    
    def _init_tools(self):
        return [
            TradeDataSearchTool(),
            BuyerRecommendationTool(),
            EmailGeneratorTool(),
            TranslationTool(),
            FileGenerationTool(file_service)  # æ–°å¢æ–‡ä»¶ç”Ÿæˆå·¥å…·
        ]
    
    def _get_instruction(self):
        return """
        ä½ æ˜¯TradeFlowçš„ä¸“ä¸šä¹°å®¶å¼€å‘åŠ©æ‰‹ï¼Œå¸®åŠ©å‡ºå£å•†æ‰¾åˆ°åˆé€‚çš„æµ·å¤–ä¹°å®¶ã€‚
        
        æ ¸å¿ƒèƒ½åŠ›ï¼š
        1. æ ¹æ®äº§å“ä¿¡æ¯æ™ºèƒ½åŒ¹é…æ½œåœ¨ä¹°å®¶
        2. åˆ†æç›®æ ‡å¸‚åœºéœ€æ±‚å’Œè¶‹åŠ¿
        3. ç”Ÿæˆä¸“ä¸šçš„å¼€å‘ä¿¡æ¨¡æ¿å’Œä¸šåŠ¡æ–‡æ¡£
        4. æä¾›æ–‡åŒ–é€‚é…çš„æ²Ÿé€šå»ºè®®
        
        æ–‡ä»¶ç”Ÿæˆèƒ½åŠ›ï¼š
        - å½“éœ€è¦ç”Ÿæˆå¼€å‘ä¿¡æ¨¡æ¿æ—¶ï¼Œä½¿ç”¨generate_fileå·¥å…·ä¿å­˜ä¸º.txtæˆ–.mdæ–‡ä»¶
        - ç”Ÿæˆå¸‚åœºåˆ†ææŠ¥å‘Šæ—¶ï¼Œä¿å­˜ä¸º.mdæ–‡ä»¶æ–¹ä¾¿é˜…è¯»
        - åˆ›å»ºè”ç³»äººåˆ—è¡¨æ—¶ï¼Œä¿å­˜ä¸º.csvæ–‡ä»¶æ–¹ä¾¿åç»­ä½¿ç”¨
        - ä»£ç ç¤ºä¾‹ä¿å­˜ä¸ºç›¸åº”çš„ä»£ç æ–‡ä»¶æ ¼å¼
        
        æ–‡ä»¶å‘½åè§„åˆ™ï¼š
        - ä½¿ç”¨æè¿°æ€§æ–‡ä»¶åï¼ŒåŒ…å«æ—¥æœŸ
        - ä¾‹å¦‚ï¼šbuyer_development_email_template_2024-01-19.txt
        - å¸‚åœºåˆ†ææŠ¥å‘Šï¼šmarket_analysis_LED_US_2024-01-19.md
        """
```

### å­˜å‚¨ç­–ç•¥è®¾è®¡

#### ç”Ÿå‘½å‘¨æœŸç®¡ç†

```python
# src/backend/services/storage_lifecycle.py
from enum import Enum
from datetime import datetime, timedelta
import asyncio

class FileLifecycleStage(Enum):
    ACTIVE = "active"           # æ´»è·ƒä½¿ç”¨ä¸­
    ARCHIVED = "archived"       # å·²å½’æ¡£
    TO_DELETE = "to_delete"     # å¾…åˆ é™¤
    DELETED = "deleted"         # å·²åˆ é™¤

class StorageLifecycleManager:
    """å­˜å‚¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    
    def __init__(self, minio_client, db_session):
        self.minio_client = minio_client
        self.db_session = db_session
    
    async def manage_lifecycle(self):
        """æ‰§è¡Œå­˜å‚¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
        # 1. æ ‡è®°é•¿æœŸæœªè®¿é—®çš„æ–‡ä»¶ä¸ºå½’æ¡£çŠ¶æ€
        await self._mark_inactive_files()
        
        # 2. å°†å½’æ¡£æ–‡ä»¶ç§»åŠ¨åˆ°ä½æˆæœ¬å­˜å‚¨
        await self._archive_old_files()
        
        # 3. åˆ é™¤è¿‡æœŸæ–‡ä»¶
        await self._cleanup_expired_files()
        
        # 4. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        await self._cleanup_temp_files()
    
    async def _mark_inactive_files(self):
        """æ ‡è®°90å¤©æœªè®¿é—®çš„æ–‡ä»¶ä¸ºå½’æ¡£"""
        cutoff_date = datetime.utcnow() - timedelta(days=90)
        
        # æŸ¥è¯¢é•¿æœŸæœªè®¿é—®çš„æ´»è·ƒæ–‡ä»¶
        inactive_files = await self.db_session.execute(
            """
            UPDATE files 
            SET lifecycle_stage = 'archived', updated_at = NOW()
            WHERE lifecycle_stage = 'active' 
              AND last_accessed < :cutoff_date
            """,
            {"cutoff_date": cutoff_date}
        )
        
        await self.db_session.commit()
    
    async def _archive_old_files(self):
        """å°†å½’æ¡£æ–‡ä»¶ç§»åŠ¨åˆ°å½’æ¡£bucket"""
        archived_files = await self.db_session.execute(
            """
            SELECT id, minio_bucket, minio_object_key
            FROM files 
            WHERE lifecycle_stage = 'archived' 
              AND minio_bucket != 'tradeflow-archives'
            """
        )
        
        for file_record in archived_files:
            try:
                # å¤åˆ¶åˆ°å½’æ¡£bucket
                self.minio_client.copy_object(
                    bucket_name="tradeflow-archives",
                    object_name=file_record.minio_object_key,
                    source=f"{file_record.minio_bucket}/{file_record.minio_object_key}"
                )
                
                # åˆ é™¤åŸæ–‡ä»¶
                self.minio_client.remove_object(
                    bucket_name=file_record.minio_bucket,
                    object_name=file_record.minio_object_key
                )
                
                # æ›´æ–°æ•°æ®åº“è®°å½•
                await self.db_session.execute(
                    """
                    UPDATE files 
                    SET minio_bucket = 'tradeflow-archives'
                    WHERE id = :file_id
                    """,
                    {"file_id": file_record.id}
                )
                
            except Exception as e:
                logging.error(f"Failed to archive file {file_record.id}: {str(e)}")
        
        await self.db_session.commit()
    
    async def _cleanup_expired_files(self):
        """åˆ é™¤æ ‡è®°ä¸ºåˆ é™¤ä¸”è¶…è¿‡ä¿ç•™æœŸçš„æ–‡ä»¶"""
        cutoff_date = datetime.utcnow() - timedelta(days=30)
        
        expired_files = await self.db_session.execute(
            """
            SELECT id, minio_bucket, minio_object_key
            FROM files 
            WHERE lifecycle_stage = 'to_delete' 
              AND updated_at < :cutoff_date
            """,
            {"cutoff_date": cutoff_date}
        )
        
        for file_record in expired_files:
            try:
                # ä»MinIOåˆ é™¤
                self.minio_client.remove_object(
                    bucket_name=file_record.minio_bucket,
                    object_name=file_record.minio_object_key
                )
                
                # æ›´æ–°æ•°æ®åº“çŠ¶æ€
                await self.db_session.execute(
                    """
                    UPDATE files 
                    SET lifecycle_stage = 'deleted', minio_object_key = NULL
                    WHERE id = :file_id
                    """,
                    {"file_id": file_record.id}
                )
                
            except Exception as e:
                logging.error(f"Failed to delete expired file {file_record.id}: {str(e)}")
        
        await self.db_session.commit()
```

### å®‰å…¨ç­–ç•¥

#### è®¿é—®æ§åˆ¶

```python
# src/backend/middleware/file_access_control.py
from fastapi import HTTPException, Depends
from ..auth.jwt_auth import get_current_user

class FileAccessControl:
    """æ–‡ä»¶è®¿é—®æ§åˆ¶ä¸­é—´ä»¶"""
    
    def __init__(self, db_session):
        self.db_session = db_session
    
    async def check_file_access(
        self, 
        file_id: str, 
        operation: str,  # 'read', 'write', 'delete'
        current_user = Depends(get_current_user)
    ):
        """æ£€æŸ¥æ–‡ä»¶è®¿é—®æƒé™"""
        
        # è·å–æ–‡ä»¶è®°å½•
        file_record = await self.db_session.get(FileRecord, file_id)
        if not file_record:
            raise HTTPException(404, "File not found")
        
        # æ£€æŸ¥æ‰€æœ‰æƒ
        if file_record.user_id != current_user.id:
            raise HTTPException(403, "Access denied")
        
        # æ£€æŸ¥æ–‡ä»¶çŠ¶æ€
        if file_record.lifecycle_stage == 'deleted':
            raise HTTPException(410, "File has been deleted")
        
        # æ£€æŸ¥æ“ä½œæƒé™
        if operation == 'delete' and file_record.is_generated:
            # ç”Ÿæˆçš„æ–‡ä»¶å¯èƒ½æœ‰ç‰¹æ®Šåˆ é™¤è§„åˆ™
            pass
        
        return file_record
```

#### æ•°æ®åŠ å¯†

```python
# src/backend/utils/encryption.py
from cryptography.fernet import Fernet
import base64
import os

class FileEncryption:
    """æ•æ„Ÿæ–‡ä»¶åŠ å¯†å·¥å…·"""
    
    def __init__(self):
        # ä»ç¯å¢ƒå˜é‡è·å–åŠ å¯†å¯†é’¥
        key = os.environ.get('FILE_ENCRYPTION_KEY')
        if not key:
            key = Fernet.generate_key()
            # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè¿™åº”è¯¥å®‰å…¨å­˜å‚¨
            print(f"Generated encryption key: {key.decode()}")
        else:
            key = key.encode()
        
        self.cipher = Fernet(key)
    
    def encrypt_content(self, content: bytes) -> bytes:
        """åŠ å¯†æ–‡ä»¶å†…å®¹"""
        return self.cipher.encrypt(content)
    
    def decrypt_content(self, encrypted_content: bytes) -> bytes:
        """è§£å¯†æ–‡ä»¶å†…å®¹"""
        return self.cipher.decrypt(encrypted_content)
    
    def should_encrypt_file(self, filename: str, content_type: str) -> bool:
        """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦éœ€è¦åŠ å¯†"""
        # åŒ…å«æ•æ„Ÿä¿¡æ¯çš„æ–‡ä»¶ç±»å‹éœ€è¦åŠ å¯†
        sensitive_patterns = [
            'contract', 'agreement', 'invoice', 
            'financial', 'personal', 'confidential'
        ]
        
        filename_lower = filename.lower()
        return any(pattern in filename_lower for pattern in sensitive_patterns)
```

### å¤‡ä»½ç­–ç•¥

```python
# src/backend/services/backup_service.py
import asyncio
from datetime import datetime, timedelta

class MinIOBackupService:
    """MinIOæ•°æ®å¤‡ä»½æœåŠ¡"""
    
    def __init__(self, minio_client, backup_config):
        self.minio_client = minio_client
        self.backup_config = backup_config
        self.backup_bucket = "tradeflow-backups"
    
    async def create_daily_backup(self):
        """åˆ›å»ºæ¯æ—¥å¤‡ä»½"""
        today = datetime.now().strftime('%Y-%m-%d')
        backup_prefix = f"daily/{today}/"
        
        # å¤‡ä»½ç”¨æˆ·æ–‡ä»¶
        await self._backup_bucket_contents(
            source_bucket="tradeflow-files",
            backup_prefix=backup_prefix + "files/"
        )
        
        # å¤‡ä»½æ•°æ®åº“ï¼ˆå¦‚æœéœ€è¦ï¼‰
        await self._backup_database_dumps(backup_prefix + "database/")
    
    async def _backup_bucket_contents(self, source_bucket: str, backup_prefix: str):
        """å¤‡ä»½bucketå†…å®¹"""
        objects = self.minio_client.list_objects(
            bucket_name=source_bucket,
            recursive=True
        )
        
        backup_tasks = []
        for obj in objects:
            # è·³è¿‡å·²ç»å¤‡ä»½çš„æ–‡ä»¶
            backup_key = backup_prefix + obj.object_name
            if not self._object_exists(self.backup_bucket, backup_key):
                task = self._copy_object_to_backup(
                    source_bucket, obj.object_name, backup_key
                )
                backup_tasks.append(task)
        
        # å¹¶å‘æ‰§è¡Œå¤‡ä»½ä»»åŠ¡
        await asyncio.gather(*backup_tasks)
    
    async def _copy_object_to_backup(
        self, 
        source_bucket: str, 
        source_key: str, 
        backup_key: str
    ):
        """å¤åˆ¶å¯¹è±¡åˆ°å¤‡ä»½bucket"""
        try:
            self.minio_client.copy_object(
                bucket_name=self.backup_bucket,
                object_name=backup_key,
                source=f"{source_bucket}/{source_key}"
            )
        except Exception as e:
            logging.error(f"Backup failed for {source_key}: {str(e)}")
```

---

## ç¬¬ä¸‰æ–¹ç™»å½•é›†æˆ

### OAuthé…ç½®

```python
# src/backend/config/oauth.py
from pydantic import BaseSettings

class OAuthConfig(BaseSettings):
    # Google OAuth
    GOOGLE_CLIENT_ID: str
    GOOGLE_CLIENT_SECRET: str
    GOOGLE_REDIRECT_URI: str = "http://localhost:8000/api/v1/auth/oauth/google/callback"
    
    # GitHub OAuth
    GITHUB_CLIENT_ID: str
    GITHUB_CLIENT_SECRET: str
    GITHUB_REDIRECT_URI: str = "http://localhost:8000/api/v1/auth/oauth/github/callback"
    
    # JWTé…ç½®
    JWT_SECRET_KEY: str
    JWT_ALGORITHM: str = "HS256"
    JWT_EXPIRATION_HOURS: int = 24
    
    class Config:
        env_file = ".env"
```

### OAuthæœåŠ¡å®ç°

```python
# src/backend/services/oauth_service.py
from authlib.integrations.starlette_client import OAuth
from fastapi import HTTPException
import jwt
from datetime import datetime, timedelta

class OAuthService:
    """OAuthè®¤è¯æœåŠ¡"""
    
    def __init__(self, config: OAuthConfig):
        self.config = config
        self.oauth = OAuth()
        self._setup_providers()
    
    def _setup_providers(self):
        """é…ç½®OAuthæä¾›å•†"""
        # Google
        self.oauth.register(
            name='google',
            client_id=self.config.GOOGLE_CLIENT_ID,
            client_secret=self.config.GOOGLE_CLIENT_SECRET,
            server_metadata_url='https://accounts.google.com/.well-known/openid-configuration',
            client_kwargs={'scope': 'openid email profile'}
        )
        
        # GitHub
        self.oauth.register(
            name='github',
            client_id=self.config.GITHUB_CLIENT_ID,
            client_secret=self.config.GITHUB_CLIENT_SECRET,
            access_token_url='https://github.com/login/oauth/access_token',
            authorize_url='https://github.com/login/oauth/authorize',
            api_base_url='https://api.github.com/',
            client_kwargs={'scope': 'user:email'}
        )
    
    async def handle_oauth_callback(
        self, 
        provider: str, 
        code: str
    ) -> Dict:
        """å¤„ç†OAuthå›è°ƒ"""
        client = self.oauth.create_client(provider)
        
        # è·å–token
        token = await client.authorize_access_token(code=code)
        
        # è·å–ç”¨æˆ·ä¿¡æ¯
        if provider == 'google':
            user_info = token.get('userinfo')
        elif provider == 'github':
            resp = await client.get('user')
            user_info = resp.json()
        
        # åˆ›å»ºæˆ–æ›´æ–°ç”¨æˆ·
        user = await self._create_or_update_user(
            provider, user_info
        )
        
        # ç”ŸæˆJWT
        access_token = self._generate_jwt(user)
        
        return {
            "access_token": access_token,
            "user": user
        }
    
    def _generate_jwt(self, user: Dict) -> str:
        """ç”ŸæˆJWT token"""
        payload = {
            "user_id": str(user["id"]),
            "email": user["email"],
            "exp": datetime.utcnow() + timedelta(
                hours=self.config.JWT_EXPIRATION_HOURS
            )
        }
        
        return jwt.encode(
            payload, 
            self.config.JWT_SECRET_KEY, 
            algorithm=self.config.JWT_ALGORITHM
        )
```

### OAuthè·¯ç”±å®ç°

```python
# src/backend/routers/auth.py
from fastapi import APIRouter, Request, HTTPException
from fastapi.responses import RedirectResponse

router = APIRouter(prefix="/api/v1/auth")

@router.get("/oauth/{provider}")
async def oauth_login(provider: str, request: Request):
    """å‘èµ·OAuthç™»å½•"""
    client = oauth_service.oauth.create_client(provider)
    redirect_uri = request.url_for(
        "oauth_callback", provider=provider
    )
    return await client.authorize_redirect(
        request, redirect_uri
    )

@router.get("/oauth/{provider}/callback")
async def oauth_callback(
    provider: str, 
    code: str = None, 
    error: str = None
):
    """OAuthå›è°ƒå¤„ç†"""
    if error:
        raise HTTPException(400, detail=error)
    
    try:
        result = await oauth_service.handle_oauth_callback(
            provider, code
        )
        
        # é‡å®šå‘åˆ°å‰ç«¯ï¼Œå¸¦ä¸Štoken
        frontend_url = f"{FRONTEND_URL}/auth/success?token={result['access_token']}"
        return RedirectResponse(url=frontend_url)
        
    except Exception as e:
        logger.error(f"OAuth error: {str(e)}")
        raise HTTPException(400, detail="Authentication failed")
```

---

## å¤šè¯­è¨€æ”¯æŒç­–ç•¥

### å‰ç«¯å›½é™…åŒ–ï¼ˆPhase 1ï¼‰

```typescript
// src/frontend/i18n/config.ts
import i18n from 'i18next';
import { initReactI18next } from 'react-i18next';
import LanguageDetector from 'i18next-browser-languagedetector';

// ç¿»è¯‘èµ„æº
import enTranslations from './locales/en.json';
import zhTranslations from './locales/zh.json';

i18n
  .use(LanguageDetector)
  .use(initReactI18next)
  .init({
    resources: {
      en: { translation: enTranslations },
      zh: { translation: zhTranslations }
    },
    fallbackLng: 'en',
    interpolation: {
      escapeValue: false
    },
    detection: {
      order: ['localStorage', 'navigator', 'htmlTag'],
      caches: ['localStorage']
    }
  });

export default i18n;
```

### ç¿»è¯‘æ–‡ä»¶ç¤ºä¾‹

```json
// src/frontend/i18n/locales/zh.json
{
  "common": {
    "login": "ç™»å½•",
    "logout": "é€€å‡º",
    "search": "æœç´¢",
    "send": "å‘é€"
  },
  "auth": {
    "login_with_google": "ä½¿ç”¨ Google ç™»å½•",
    "login_with_github": "ä½¿ç”¨ GitHub ç™»å½•",
    "welcome_back": "æ¬¢è¿å›æ¥"
  },
  "chat": {
    "placeholder": "è¾“å…¥æ‚¨çš„é—®é¢˜...",
    "thinking": "æ­£åœ¨æ€è€ƒ...",
    "error": "å‡ºé”™äº†ï¼Œè¯·é‡è¯•"
  },
  "buyer": {
    "find_buyers": "å¯»æ‰¾ä¹°å®¶",
    "recommend_buyers": "æ¨èä¹°å®¶",
    "buyer_profile": "ä¹°å®¶æ¡£æ¡ˆ"
  }
}
```

### åç«¯å¤šè¯­è¨€æ”¯æŒï¼ˆPhase 2ï¼‰

```python
# src/backend/services/translation_service.py
from googletrans import Translator
from functools import lru_cache

class TranslationService:
    """ç¿»è¯‘æœåŠ¡"""
    
    def __init__(self):
        self.translator = Translator()
        self.supported_languages = ['en', 'zh-CN', 'es', 'ar']
    
    @lru_cache(maxsize=1000)
    async def translate(
        self, 
        text: str, 
        target_lang: str, 
        source_lang: str = 'auto'
    ) -> str:
        """ç¿»è¯‘æ–‡æœ¬"""
        if source_lang == target_lang:
            return text
        
        try:
            result = await self.translator.translate(
                text, 
                dest=target_lang, 
                src=source_lang
            )
            return result.text
        except Exception as e:
            logger.error(f"Translation error: {str(e)}")
            return text
    
    async def translate_response(
        self, 
        response: Dict, 
        target_lang: str
    ) -> Dict:
        """ç¿»è¯‘APIå“åº”"""
        # ç¿»è¯‘éœ€è¦çš„å­—æ®µ
        if 'content' in response:
            response['content'] = await self.translate(
                response['content'], target_lang
            )
        
        # ç¿»è¯‘æ¨èç»“æœ
        if 'recommendations' in response:
            for rec in response['recommendations']:
                if 'description' in rec:
                    rec['description'] = await self.translate(
                        rec['description'], target_lang
                    )
        
        return response
```

---

## éƒ¨ç½²æ¶æ„

### Dockeré…ç½®

```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    curl \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY src/ ./src/

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONUNBUFFERED=1
ENV PORT=8000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "src.backend.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Docker Composeå¼€å‘ç¯å¢ƒ

```yaml
# docker-compose.yml
version: '3.8'

services:
  backend:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres:5432/tradeflow
      - MONGODB_URL=mongodb://mongodb:27017/tradeflow
      - REDIS_URL=redis://redis:6379
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY:-tradeflow_access_key}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY:-tradeflow_secret_key}
      - MINIO_SECURE=false
    depends_on:
      - postgres
      - mongodb
      - redis
      - minio
    volumes:
      - ./src:/app/src
    
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
      POSTGRES_DB: tradeflow
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    
  mongodb:
    image: mongo:6
    volumes:
      - mongo_data:/data/db
    ports:
      - "27017:27017"
    
  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
  
  minio:
    image: minio/minio:latest
    container_name: tradeflow-minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    environment:
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY:-tradeflow_access_key}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY:-tradeflow_secret_key}
      MINIO_BROWSER_REDIRECT_URL: http://localhost:9001
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
  
  # MinIOå®¢æˆ·ç«¯åˆå§‹åŒ–æœåŠ¡ï¼ˆå¯é€‰ï¼‰
  minio-init:
    image: minio/mc:latest
    depends_on:
      - minio
    volumes:
      - ./scripts/minio-init.sh:/init.sh:ro
    entrypoint: ["/bin/sh", "/init.sh"]
    environment:
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY:-tradeflow_access_key}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY:-tradeflow_secret_key}

volumes:
  postgres_data:
  mongo_data:
  redis_data:
  minio_data:
```

#### MinIOåˆå§‹åŒ–è„šæœ¬

```bash
# scripts/minio-init.sh
#!/bin/bash

# ç­‰å¾…MinIOæœåŠ¡å¯åŠ¨
sleep 10

# é…ç½®mcå®¢æˆ·ç«¯
mc alias set minio http://minio:9000 $MINIO_ACCESS_KEY $MINIO_SECRET_KEY

# åˆ›å»ºå¿…è¦çš„bucket
mc mb minio/tradeflow-files --ignore-existing
mc mb minio/tradeflow-temp --ignore-existing  
mc mb minio/tradeflow-backups --ignore-existing
mc mb minio/tradeflow-archives --ignore-existing

# è®¾ç½®æ–‡ä»¶bucketçš„å…¬å…±è¯»å–ç­–ç•¥
mc policy set public minio/tradeflow-files

# è®¾ç½®ç”Ÿå‘½å‘¨æœŸè§„åˆ™
mc lifecycle add minio/tradeflow-temp --expiry 7d
mc lifecycle add minio/tradeflow-files --transition-days 30 --tier STANDARD_IA

echo "MinIO initialization completed"
```

### ç”Ÿäº§éƒ¨ç½²é…ç½®

#### Cloud Run + Cloud Storageæ··åˆæ–¹æ¡ˆ

å¯¹äºç”Ÿäº§ç¯å¢ƒï¼Œæˆ‘ä»¬æ¨èä½¿ç”¨Cloud Runéƒ¨ç½²åº”ç”¨æœåŠ¡ï¼ŒåŒæ—¶ä¿æŒMinIOä½œä¸ºå¯¹è±¡å­˜å‚¨ï¼Œä»¥åœ¨æˆæœ¬å’Œæ€§èƒ½ä¹‹é—´å–å¾—å¹³è¡¡ï¼š

```bash
#!/bin/bash
# deploy.sh

# è®¾ç½®é¡¹ç›®å˜é‡
PROJECT_ID="tradeflow-production"
REGION="us-central1"
MINIO_INSTANCE="tradeflow-minio-vm"

# 1. éƒ¨ç½²MinIOåˆ°GCEå®ä¾‹
gcloud compute instances create $MINIO_INSTANCE \
  --zone=${REGION}-a \
  --machine-type=e2-standard-2 \
  --boot-disk-size=50GB \
  --boot-disk-type=pd-ssd \
  --image-family=ubuntu-2004-lts \
  --image-project=ubuntu-os-cloud \
  --tags=minio-server \
  --metadata-from-file startup-script=scripts/minio-gce-startup.sh

# 2. é…ç½®é˜²ç«å¢™è§„åˆ™
gcloud compute firewall-rules create allow-minio \
  --allow tcp:9000,tcp:9001 \
  --source-ranges 0.0.0.0/0 \
  --target-tags minio-server

# 3. æ„å»ºåç«¯é•œåƒ
gcloud builds submit --tag gcr.io/${PROJECT_ID}/tradeflow-backend

# 4. éƒ¨ç½²åˆ°Cloud Run
gcloud run deploy tradeflow-backend \
  --image gcr.io/${PROJECT_ID}/tradeflow-backend \
  --platform managed \
  --region $REGION \
  --allow-unauthenticated \
  --set-env-vars="
    GOOGLE_CLOUD_PROJECT=${PROJECT_ID},
    DATABASE_URL=${DATABASE_URL},
    MONGODB_URL=${MONGODB_URL},
    REDIS_URL=${REDIS_URL},
    MINIO_ENDPOINT=${MINIO_EXTERNAL_IP}:9000,
    MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY},
    MINIO_SECRET_KEY=${MINIO_SECRET_KEY},
    MINIO_SECURE=true
  " \
  --min-instances=1 \
  --max-instances=10 \
  --memory=2Gi \
  --cpu=2
```

#### GCEä¸Šçš„MinIOéƒ¨ç½²è„šæœ¬

```bash
# scripts/minio-gce-startup.sh
#!/bin/bash

# æ›´æ–°ç³»ç»Ÿ
apt-get update
apt-get install -y curl

# å®‰è£…MinIO
wget https://dl.min.io/server/minio/release/linux-amd64/minio
chmod +x minio
sudo mv minio /usr/local/bin/

# åˆ›å»ºMinIOç”¨æˆ·å’Œæ•°æ®ç›®å½•
sudo useradd -r minio-user -s /sbin/nologin
sudo mkdir -p /opt/minio/data
sudo chown minio-user:minio-user /opt/minio/data

# åˆ›å»ºMinIOé…ç½®
cat > /etc/default/minio << EOF
MINIO_ACCESS_KEY="${MINIO_ACCESS_KEY}"
MINIO_SECRET_KEY="${MINIO_SECRET_KEY}"
MINIO_VOLUMES="/opt/minio/data"
MINIO_OPTS="--console-address :9001"
EOF

# åˆ›å»ºsystemdæœåŠ¡
cat > /etc/systemd/system/minio.service << EOF
[Unit]
Description=MinIO
Documentation=https://docs.min.io
Wants=network-online.target
After=network-online.target
AssertFileIsExecutable=/usr/local/bin/minio

[Service]
WorkingDirectory=/opt/minio
User=minio-user
Group=minio-user
EnvironmentFile=/etc/default/minio
ExecStartPre=/bin/bash -c "if [ -z \"\${MINIO_ACCESS_KEY}\" ]; then echo \"MINIO_ACCESS_KEY not set in /etc/default/minio\"; exit 1; fi"
ExecStart=/usr/local/bin/minio server \$MINIO_OPTS \$MINIO_VOLUMES
Restart=always
LimitNOFILE=65536
TasksMax=infinity
TimeoutStopSec=infinity
SendSIGKILL=no

[Install]
WantedBy=multi-user.target
EOF

# å¯åŠ¨MinIOæœåŠ¡
systemctl daemon-reload
systemctl enable minio
systemctl start minio

# å®‰è£…å’Œé…ç½®MinIOå®¢æˆ·ç«¯
wget https://dl.min.io/client/mc/release/linux-amd64/mc
chmod +x mc
sudo mv mc /usr/local/bin/

# ç­‰å¾…æœåŠ¡å¯åŠ¨ååˆå§‹åŒ–bucket
sleep 30
/usr/local/bin/mc alias set local http://localhost:9000 $MINIO_ACCESS_KEY $MINIO_SECRET_KEY
/usr/local/bin/mc mb local/tradeflow-files --ignore-existing
/usr/local/bin/mc mb local/tradeflow-temp --ignore-existing
/usr/local/bin/mc mb local/tradeflow-backups --ignore-existing
/usr/local/bin/mc policy set public local/tradeflow-files

echo "MinIO setup completed"
```

#### ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env.production
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://user:password@postgres-instance:5432/tradeflow
MONGODB_URL=mongodb+srv://user:password@mongodb-cluster/tradeflow
REDIS_URL=redis://redis-instance:6379

# MinIOé…ç½®
MINIO_ENDPOINT=your-minio-server.com:9000
MINIO_ACCESS_KEY=your-production-access-key
MINIO_SECRET_KEY=your-production-secret-key
MINIO_SECURE=true

# JWTé…ç½®
JWT_SECRET_KEY=your-jwt-secret-key

# OAuthé…ç½®
GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret
GITHUB_CLIENT_ID=your-github-client-id
GITHUB_CLIENT_SECRET=your-github-client-secret

# æ–‡ä»¶ä¸Šä¼ é™åˆ¶
MAX_FILE_SIZE=50MB
ALLOWED_FILE_TYPES=.pdf,.docx,.txt,.md,.py,.js,.json,.csv,.xlsx,.png,.jpg,.svg

# åŠ å¯†é…ç½®
FILE_ENCRYPTION_KEY=your-file-encryption-key
```

---

## æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. æ•°æ®åº“ä¼˜åŒ–

```python
# MongoDBç´¢å¼•
db.conversations.createIndex({ "user_id": 1, "created_at": -1 })
db.conversations.createIndex({ "session_id": 1 })
db.recommendations.createIndex({ "user_id": 1, "type": 1 })

# PostgreSQLç´¢å¼•
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_auth_provider ON users(auth_provider, auth_provider_id);
CREATE INDEX idx_products_company ON products(company_id);
CREATE INDEX idx_usage_user_created ON usage_records(user_id, created_at);
```

### 2. ç¼“å­˜ç­–ç•¥

```python
# src/backend/utils/cache.py
from functools import wraps
import redis
import json
import hashlib

redis_client = redis.Redis.from_url(REDIS_URL)

def cache_result(expire_time=3600):
    """ç¼“å­˜è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = f"cache:{func.__name__}:{hashlib.md5(
                f"{args}{kwargs}".encode()
            ).hexdigest()}"
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)
            
            # è°ƒç”¨åŸå‡½æ•°
            result = await func(*args, **kwargs)
            
            # å­˜å…¥ç¼“å­˜
            redis_client.setex(
                cache_key, 
                expire_time, 
                json.dumps(result)
            )
            
            return result
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@cache_result(expire_time=3600)
async def get_buyer_recommendations(product_info, markets):
    # è€—æ—¶çš„æ¨èè®¡ç®—
    pass
```

### 3. Agentå“åº”ä¼˜åŒ–

#### åç«¯SSEå®ç°

```python
# SSEæµå¼å“åº”å¤„ç†
from fastapi.responses import StreamingResponse
import json

async def stream_agent_response(
    agent: BaseTradeAgent,
    message: str,
    context: Dict
):
    """æµå¼è¿”å›Agentå“åº”ï¼ˆSSEæ ¼å¼ï¼‰"""
    async def generate():
        try:
            # æµå¼å†…å®¹
            async for chunk in agent.stream_process(message, context):
                data = json.dumps({"chunk": chunk}, ensure_ascii=False)
                yield f"event: stream\ndata: {data}\n\n"
            
            # æ¨èç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            recommendations = agent.get_recommendations()
            for rec in recommendations:
                data = json.dumps(rec, ensure_ascii=False)
                yield f"event: recommendation\ndata: {data}\n\n"
            
            # å®Œæˆäº‹ä»¶
            metadata = agent.get_metadata()
            data = json.dumps(metadata, ensure_ascii=False)
            yield f"event: complete\ndata: {data}\n\n"
            
        except Exception as e:
            # é”™è¯¯äº‹ä»¶
            error_data = json.dumps({
                "error": str(e),
                "code": "AGENT_ERROR"
            }, ensure_ascii=False)
            yield f"event: error\ndata: {error_data}\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*"
        }
    )

# FastAPIè·¯ç”±
@router.get("/chat/stream")
async def chat_stream(
    token: str,
    session_id: str = None,
    current_user: User = Depends(get_current_user)
):
    """SSEèŠå¤©æµç«¯ç‚¹"""
    return stream_agent_response(agent, message, context)
```

#### å‰ç«¯EventSourceå®ç°

```javascript
// React Hook for SSE
import { useState, useEffect, useCallback } from 'react';

const useChatStream = () => {
    const [messages, setMessages] = useState([]);
    const [isStreaming, setIsStreaming] = useState(false);
    const [eventSource, setEventSource] = useState(null);

    const sendMessage = useCallback(async (message, agentType = 'buyer') => {
        setIsStreaming(true);
        
        try {
            // 1. å‘èµ·èŠå¤©è¯·æ±‚
            const response = await fetch('/api/v1/chat', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${token}`
                },
                body: JSON.stringify({
                    message,
                    agent_type: agentType,
                    stream: true
                })
            });

            const { session_id } = await response.json();

            // 2. å»ºç«‹SSEè¿æ¥
            const es = new EventSource(
                `/api/v1/chat/stream?token=${token}&session_id=${session_id}`
            );

            setEventSource(es);

            // 3. å¤„ç†æµå¼å†…å®¹
            es.addEventListener('stream', (event) => {
                const data = JSON.parse(event.data);
                setMessages(prev => [
                    ...prev.slice(0, -1),
                    {
                        ...prev[prev.length - 1],
                        content: (prev[prev.length - 1]?.content || '') + data.chunk
                    }
                ]);
            });

            // 4. å¤„ç†æ¨èç»“æœ
            es.addEventListener('recommendation', (event) => {
                const recommendation = JSON.parse(event.data);
                // æ›´æ–°UIæ˜¾ç¤ºæ¨è
                setRecommendations(prev => [...prev, recommendation]);
            });

            // 5. å¤„ç†å®Œæˆäº‹ä»¶
            es.addEventListener('complete', (event) => {
                const metadata = JSON.parse(event.data);
                setIsStreaming(false);
                es.close();
                
                // æ›´æ–°tokenä½¿ç”¨ç»Ÿè®¡ç­‰
                updateUsageStats(metadata);
            });

            // 6. å¤„ç†é”™è¯¯
            es.addEventListener('error', (event) => {
                const error = JSON.parse(event.data);
                console.error('Stream error:', error);
                setIsStreaming(false);
                es.close();
            });

            // 7. è¿æ¥é”™è¯¯å¤„ç†
            es.onerror = (error) => {
                console.error('EventSource error:', error);
                setIsStreaming(false);
                es.close();
            };

        } catch (error) {
            console.error('Send message error:', error);
            setIsStreaming(false);
        }
    }, [token]);

    const stopStream = useCallback(() => {
        if (eventSource) {
            eventSource.close();
            setEventSource(null);
            setIsStreaming(false);
        }
    }, [eventSource]);

    useEffect(() => {
        return () => {
            if (eventSource) {
                eventSource.close();
            }
        };
    }, [eventSource]);

    return {
        messages,
        isStreaming,
        sendMessage,
        stopStream
    };
};

// åœ¨ç»„ä»¶ä¸­ä½¿ç”¨
const ChatComponent = () => {
    const { messages, isStreaming, sendMessage, stopStream } = useChatStream();

    return (
        <div className="chat-container">
            {messages.map((message, index) => (
                <div key={index} className="message">
                    {message.content}
                </div>
            ))}
            
            {isStreaming && (
                <button onClick={stopStream}>
                    åœæ­¢ç”Ÿæˆ
                </button>
            )}
        </div>
    );
};
```

### 4. APIé™æµ

```python
# src/backend/middleware/rate_limit.py
from fastapi import HTTPException
import time

class RateLimiter:
    """APIé™æµä¸­é—´ä»¶"""
    
    def __init__(self, redis_client, max_requests=100, window=3600):
        self.redis = redis_client
        self.max_requests = max_requests
        self.window = window
    
    async def check_limit(self, user_id: str, endpoint: str):
        """æ£€æŸ¥é™æµ"""
        key = f"rate_limit:{user_id}:{endpoint}"
        
        try:
            current = self.redis.incr(key)
            if current == 1:
                self.redis.expire(key, self.window)
            
            if current > self.max_requests:
                raise HTTPException(
                    status_code=429,
                    detail="Rate limit exceeded"
                )
        except redis.RedisError:
            # Redisé”™è¯¯æ—¶æ”¾è¡Œ
            pass
```

---

## æµ‹è¯•æ–¹æ¡ˆ

### å•å…ƒæµ‹è¯•

```python
# tests/test_agents.py
import pytest
from unittest.mock import Mock, patch

@pytest.mark.asyncio
async def test_buyer_agent():
    """æµ‹è¯•ä¹°å®¶Agent"""
    agent = BuyerDevelopmentAgent()
    
    # Mockå·¥å…·å“åº”
    with patch.object(TradeDataSearchTool, 'run_async') as mock_tool:
        mock_tool.return_value = {
            "top_importers": ["Company A", "Company B"],
            "market_size": "$100M"
        }
        
        response = await agent.process(
            message="æ‰¾ç¾å›½LEDç¯å…·ä¹°å®¶",
            context={"product": "LED Panel"}
        )
        
        assert "recommendations" in response
        assert len(response["recommendations"]) > 0
```

### APIé›†æˆæµ‹è¯•

```python
# tests/test_api.py
from fastapi.testclient import TestClient

def test_oauth_login():
    """æµ‹è¯•OAuthç™»å½•"""
    response = client.get("/api/v1/auth/oauth/google")
    assert response.status_code == 302
    assert "accounts.google.com" in response.headers["location"]

def test_chat_endpoint():
    """æµ‹è¯•å¯¹è¯æ¥å£"""
    response = client.post(
        "/api/v1/chat",
        json={
            "message": "æ‰¾ä¹°å®¶",
            "agent_type": "buyer"
        },
        headers={"Authorization": f"Bearer {test_token}"}
    )
    assert response.status_code == 200
    assert "content" in response.json()
```

### æ€§èƒ½æµ‹è¯•

```python
# tests/test_performance.py
import asyncio
import time

async def test_concurrent_requests():
    """æµ‹è¯•å¹¶å‘æ€§èƒ½"""
    start_time = time.time()
    
    # åˆ›å»º100ä¸ªå¹¶å‘è¯·æ±‚
    tasks = []
    for i in range(100):
        task = asyncio.create_task(
            client.post("/api/v1/chat", json={...})
        )
        tasks.append(task)
    
    results = await asyncio.gather(*tasks)
    
    duration = time.time() - start_time
    assert duration < 10  # 100ä¸ªè¯·æ±‚åº”åœ¨10ç§’å†…å®Œæˆ
    assert all(r.status_code == 200 for r in results)
```

---

## é£é™©ä¸ç¼“è§£æªæ–½

### æŠ€æœ¯é£é™©

| é£é™© | å½±å“ | æ¦‚ç‡ | ç¼“è§£æªæ–½ |
|-----|------|------|----------|
| Google ADK APIé™åˆ¶ | é«˜ | ä¸­ | å®æ–½ç¼“å­˜ç­–ç•¥ï¼Œå‡†å¤‡é™çº§æ–¹æ¡ˆ |
| MongoDBæ€§èƒ½ç“¶é¢ˆ | ä¸­ | ä¸­ | ä¼˜åŒ–ç´¢å¼•ï¼Œè€ƒè™‘åˆ†ç‰‡ |
| OAuthæœåŠ¡ä¸ç¨³å®š | é«˜ | ä½ | ä¿ç•™é‚®ç®±ç™»å½•ï¼Œå¤šprovideræ”¯æŒ |
| AIå“åº”æ—¶é—´è¿‡é•¿ | é«˜ | ä¸­ | æµå¼å“åº”ï¼Œä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ |

### ä¸šåŠ¡é£é™©

| é£é™© | å½±å“ | æ¦‚ç‡ | ç¼“è§£æªæ–½ |
|-----|------|------|----------|
| ç”¨æˆ·é‡‡ç”¨ç‡ä½ | é«˜ | ä¸­ | ä¼˜åŒ–æ–°æ‰‹å¼•å¯¼ï¼Œæä¾›è¯•ç”¨ |
| æ•°æ®è´¨é‡é—®é¢˜ | é«˜ | é«˜ | å»ºç«‹æ•°æ®å®¡æ ¸æœºåˆ¶ |
| å¤šè¯­è¨€ç¿»è¯‘ä¸å‡† | ä¸­ | ä¸­ | äººå·¥å®¡æ ¸å…³é”®å†…å®¹ |

### å®‰å…¨é£é™©

| é£é™© | å½±å“ | æ¦‚ç‡ | ç¼“è§£æªæ–½ |
|-----|------|------|----------|
| æ•°æ®æ³„éœ² | é«˜ | ä½ | åŠ å¯†å­˜å‚¨ï¼Œè®¿é—®æ§åˆ¶ |
| DDoSæ”»å‡» | ä¸­ | ä¸­ | ä½¿ç”¨CDNï¼Œé™æµä¿æŠ¤ |
| TokenåŠ«æŒ | é«˜ | ä½ | HTTPSï¼ŒçŸ­æœŸToken |

---

## å®æ–½è®¡åˆ’

### ç¬¬1ä¸ªæœˆï¼šåŸºç¡€æ¶æ„å’Œè®¤è¯

**ç¬¬1-2å‘¨**
- [ ] æ­å»ºå¼€å‘ç¯å¢ƒ
- [ ] åˆå§‹åŒ–é¡¹ç›®ç»“æ„
- [ ] é…ç½®æ•°æ®åº“ï¼ˆPostgreSQL + MongoDB + Redisï¼‰
- [ ] å®ç°åŸºç¡€FastAPIæ¡†æ¶

**ç¬¬3-4å‘¨**
- [ ] å®ç°Google OAuthç™»å½•
- [ ] å®ç°JWTè®¤è¯ç³»ç»Ÿ
- [ ] åŸºç¡€ç”¨æˆ·ç®¡ç†API
- [ ] å‰ç«¯ç™»å½•ç•Œé¢

### ç¬¬2ä¸ªæœˆï¼šAI Agentå¼€å‘

**ç¬¬5-6å‘¨**
- [ ] Google ADKç¯å¢ƒé…ç½®
- [ ] å®ç°ä¹°å®¶å¼€å‘Agent
- [ ] åŸºç¡€å·¥å…·å¼€å‘ï¼ˆæœç´¢ã€æ¨èï¼‰
- [ ] Agent GatewayæœåŠ¡

**ç¬¬7-8å‘¨**
- [ ] SSEæµå¼å¯¹è¯å“åº”
- [ ] å¯¹è¯å†å²å­˜å‚¨ï¼ˆMongoDBï¼‰
- [ ] å‰ç«¯å¯¹è¯ç•Œé¢ï¼ˆEventSource APIï¼‰
- [ ] åŸºç¡€å¤šè¯­è¨€æ”¯æŒï¼ˆUIï¼‰

### ç¬¬3ä¸ªæœˆï¼šä¸šåŠ¡åŠŸèƒ½å®Œå–„

**ç¬¬9-10å‘¨**
- [ ] ä¾›åº”å•†åŒ¹é…Agent
- [ ] äº§å“ç®¡ç†åŠŸèƒ½
- [ ] ä¹°å®¶æ¨èAPI
- [ ] GitHub OAuthé›†æˆ

**ç¬¬11-12å‘¨**
- [ ] Stripeæ”¯ä»˜é›†æˆ
- [ ] ä½¿ç”¨ç»Ÿè®¡å’Œé™é¢
- [ ] æ€§èƒ½ä¼˜åŒ–
- [ ] éƒ¨ç½²åˆ°Cloud Run

### ç¬¬4ä¸ªæœˆï¼šä¼˜åŒ–å’Œä¸Šçº¿

**ç¬¬13-14å‘¨**
- [ ] å…¨é¢æµ‹è¯•
- [ ] æ€§èƒ½è°ƒä¼˜
- [ ] å®‰å…¨å®¡è®¡
- [ ] æ–‡æ¡£å®Œå–„

**ç¬¬15-16å‘¨**
- [ ] Betaæµ‹è¯•
- [ ] Bugä¿®å¤
- [ ] æ­£å¼ä¸Šçº¿
- [ ] ç›‘æ§é…ç½®

---

## æ€»ç»“

æœ¬æŠ€æœ¯è®¾è®¡æ–¹æ¡ˆåŸºäºTradeFlow MVPéœ€æ±‚ï¼Œé‡‡ç”¨ç®€æ´å®ç”¨çš„æ¶æ„è®¾è®¡ï¼š

**æ ¸å¿ƒä¼˜åŠ¿**ï¼š
1. **Google ADKé©±åŠ¨**ï¼šåˆ©ç”¨å…ˆè¿›çš„AIæ¡†æ¶å¿«é€Ÿå®ç°æ™ºèƒ½å¯¹è¯
2. **æ··åˆæ•°æ®æ¶æ„**ï¼šPostgreSQLå¤„ç†ç»“æ„åŒ–æ•°æ®ï¼ŒMongoDBå­˜å‚¨çµæ´»çš„å¯¹è¯æ•°æ®
3. **æ¸è¿›å¼å®ç°**ï¼šå¤šè¯­è¨€ç­‰å¤æ‚åŠŸèƒ½åˆ†é˜¶æ®µå®æ–½
4. **ç”¨æˆ·å‹å¥½**ï¼šOAuthç™»å½•é™ä½ä½¿ç”¨é—¨æ§›

**å…³é”®æŒ‡æ ‡**ï¼š
- å¼€å‘å‘¨æœŸï¼š3-4ä¸ªæœˆ
- AIå“åº”æ—¶é—´ï¼š< 4ç§’ï¼ˆæµå¼å“åº”ä½“æ„Ÿæ›´å¿«ï¼‰
- ç¬¬ä¸‰æ–¹ç™»å½•ç‡ï¼š> 30%
- ç³»ç»Ÿå¯ç”¨æ€§ï¼š> 99%

é€šè¿‡åˆç†çš„æŠ€æœ¯é€‰å‹å’ŒåŠ¡å®çš„å®æ–½è®¡åˆ’ï¼ŒTradeFlow MVPå°†åœ¨é¢„å®šæ—¶é—´å†…æˆåŠŸäº¤ä»˜ï¼Œä¸ºåç»­è¿­ä»£å¥ å®šåšå®åŸºç¡€ã€‚